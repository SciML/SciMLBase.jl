var documenterSearchIndex = {"docs":
[{"location":"interfaces/SciMLFunctions/#scimlfunctions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLFunctions (Jacobians, Sparsity, Etc.)","text":"The SciML ecosystem provides an extensive interface for declaring extra functions associated with the differential equation's data. In traditional libraries there is usually only one option: the Jacobian. However, we allow for a large array of pre-computed functions to speed up the calculations. This is offered via the SciMLFunction types which can be passed to the problems.","category":"section"},{"location":"interfaces/SciMLFunctions/#Definition-of-the-AbstractSciMLFunction-Interface","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Definition of the AbstractSciMLFunction Interface","text":"The following standard principles should be adhered to across all AbstractSciMLFunction instantiations.","category":"section"},{"location":"interfaces/SciMLFunctions/#Common-Function-Choice-Definitions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Common Function Choice Definitions","text":"The full interface available to the solvers is as follows:\n\njac: The Jacobian of the differential equation with respect to the state variable u at a time t with parameters p.\nparamjac: The Jacobian of the differential equation with respect to p at state u at time t.\nanalytic: Defines an analytical solution using u0 at time t with p which will cause the solvers to return errors. Used for testing.\nsyms: Allows you to name your variables for automatic names in plots and other output.\njac_prototype: Defines the type to be used for any internal Jacobians within the solvers.\nsparsity: Defines the sparsity pattern to be used for the sparse differentiation schemes. By default this is equal to jac_prototype. See the sparsity handling portion of this page for more information.\ncolorvec: The coloring pattern used by the sparse differentiator. See the sparsity handling portion of this page for more information.\nobserved: A function which allows for generating other observables from a solution.\n\nEach function type additionally has some specific arguments, refer to their documentation for details.","category":"section"},{"location":"interfaces/SciMLFunctions/#In-place-Specification-and-No-Recompile-Mode","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"In-place Specification and No-Recompile Mode","text":"Each SciMLFunction type can be called with an \"is inplace\" (iip) choice.\n\nODEFunction(f)\nODEFunction{iip}(f)\n\nwhich is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferability of the AbstractSciMLProblem this iip-ness should be specified.","category":"section"},{"location":"interfaces/SciMLFunctions/#Specialization-Choices","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Specialization Choices","text":"Each SciMLFunction type allows for specialization choices\n\nODEFunction{iip, specialization}(f)\n\nwhich designates how the compiler should specialize on the model function f. For more details on specialization choices, see the SciMLProblems page.","category":"section"},{"location":"interfaces/SciMLFunctions/#Specifying-Jacobian-Types","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Specifying Jacobian Types","text":"The jac field of an inplace style SciMLFunction has the signature jac(J,u,p,t), which updates the Jacobian J in-place. The intended type for J can sometimes be inferred (e.g. when it is just a dense Matrix), but not in general. To supply the type information, you can provide a jac_prototype in the function's constructor.\n\nThe following example creates an inplace ODEFunction whose Jacobian is a Diagonal:\n\nusing LinearAlgebra\nf = (du, u, p, t) -> du .= t .* u\njac = (J, u, p, t) -> (J[1, 1] = t; J[2, 2] = t; J)\njp = Diagonal(zeros(2))\nfun = ODEFunction(f; jac = jac, jac_prototype = jp)\n\nNote that the integrators will always make a deep copy of fun.jac_prototype, so there's no worry of aliasing.\n\nIn general the jacobian prototype can be anything that has mul! defined, in particular sparse matrices or custom lazy types that support mul!. A special case is when the jac_prototype is a AbstractSciMLOperator, in which case you do not need to supply jac as it is automatically set to update_coefficients!. Refer to the SciMLOperators section for more information on setting up time/parameter dependent operators.","category":"section"},{"location":"interfaces/SciMLFunctions/#Sparsity-Handling","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Sparsity Handling","text":"The solver libraries internally use packages such as FiniteDiff.jl and SparseDiffTools.jl for high performance calculation of sparse Jacobians and Hessians, along with matrix-free calculations of Jacobian-Vector products (J*v), vector-Jacobian products (v'*J), and Hessian-vector products (H*v). The SciML interface gives users the ability to control these connections in order to allow for top notch performance.\n\nThe key arguments in the SciMLFunction is the prototype, which is an object that will be used as the underlying Jacobian/Hessian. Thus if one wants to use a sparse Jacobian, one should specify jac_prototype to be a sparse matrix. The sparsity pattern used in the differentiation scheme is defined by sparsity. By default, sparsity=jac_prototype, meaning that the sparse automatic differentiation scheme should specialize on the sparsity pattern given by the actual sparsity pattern. This can be overridden to say perform partial matrix coloring approximations. Additionally, the color vector for the sparse differentiation directions can be specified directly via colorvec. For more information on how these arguments control the differentiation process, see the aforementioned differentiation library documentations.","category":"section"},{"location":"interfaces/SciMLFunctions/#Traits","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Traits","text":"","category":"section"},{"location":"interfaces/SciMLFunctions/#AbstractSciMLFunction-API","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"AbstractSciMLFunction API","text":"","category":"section"},{"location":"interfaces/SciMLFunctions/#Abstract-SciML-Functions","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"Abstract SciML Functions","text":"","category":"section"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractDiffEqFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiffEqFunction","text":"abstract type AbstractDiffEqFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\nBase for types defining differential equation functions.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractODEFunction","text":"abstract type AbstractODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractSDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDEFunction","text":"abstract type AbstractSDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDDEFunction","text":"abstract type AbstractDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractDAEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDAEFunction","text":"abstract type AbstractDAEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractRODEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractRODEFunction","text":"abstract type AbstractRODEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractDiscreteFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractDiscreteFunction","text":"abstract type AbstractDiscreteFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractSDDEFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractSDDEFunction","text":"abstract type AbstractSDDEFunction{iip} <: SciMLBase.AbstractDiffEqFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/SciMLFunctions/#SciMLBase.AbstractNonlinearFunction","page":"SciMLFunctions (Jacobians, Sparsity, Etc.)","title":"SciMLBase.AbstractNonlinearFunction","text":"abstract type AbstractNonlinearFunction{iip} <: SciMLBase.AbstractSciMLFunction{iip}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#ensemble","page":"Parallel Ensemble Simulations Interface","title":"Parallel Ensemble Simulations Interface","text":"Performing Monte Carlo simulations, solving with a predetermined set of initial conditions, and GPU-parallelizing a parameter search all fall under the ensemble simulation interface. This interface allows one to declare a template AbstractSciMLProblem to parallelize, tweak the template in trajectories for many trajectories, solve each in parallel batches, reduce the solutions down to specific answers, and compute summary statistics on the results.","category":"section"},{"location":"interfaces/Ensembles/#Performing-an-Ensemble-Simulation","page":"Parallel Ensemble Simulations Interface","title":"Performing an Ensemble Simulation","text":"","category":"section"},{"location":"interfaces/Ensembles/#Building-a-Problem","page":"Parallel Ensemble Simulations Interface","title":"Building a Problem","text":"","category":"section"},{"location":"interfaces/Ensembles/#Solving-the-Problem","page":"Parallel Ensemble Simulations Interface","title":"Solving the Problem","text":"","category":"section"},{"location":"interfaces/Ensembles/#EnsembleAlgorithms","page":"Parallel Ensemble Simulations Interface","title":"EnsembleAlgorithms","text":"The choice of ensemble algorithm allows for control over how the multiple trajectories are handled. Currently, the ensemble algorithm types are:","category":"section"},{"location":"interfaces/Ensembles/#DiffEq-Only-(ODEProblem,-SDEProblem)","page":"Parallel Ensemble Simulations Interface","title":"DiffEq Only (ODEProblem, SDEProblem)","text":"GPU Manufacturer GPU Kernel Language Julia Support Package Backend Type\nNVIDIA CUDA CUDA.jl CUDA.CUDABackend()\nAMD ROCm AMDGPU.jl AMDGPU.ROCBackend()\nIntel OneAPI OneAPI.jl oneAPI.oneAPIBackend()\nApple (M-Series) Metal Metal.jl Metal.MetalBackend()\n\nEnsembleGPUArray() - Requires installing and using DiffEqGPU. This uses a GPU for computing the ensemble with hyperparallelism. It will automatically recompile your Julia functions to the GPU. A standard GPU sees a 5x performance increase over a 16 core Xeon CPU. However, there are limitations on what functions can auto-compile in this fashion, please see DiffEqGPU for more details\nEnsembleGPUKernel() - Requires installing and using DiffEqGPU. This uses a GPU for computing the ensemble with hyperparallelism by building a custom GPU kernel. This can have drastically less overhead (for example, achieving 15x accelerating against Jax and PyTorch, see this paper for more details) but has limitations on what kinds of problems are compatible. See DiffEqGPU for more details","category":"section"},{"location":"interfaces/Ensembles/#Choosing-an-Ensembler","page":"Parallel Ensemble Simulations Interface","title":"Choosing an Ensembler","text":"For example, EnsembleThreads() is invoked by:\n\nsolve(ensembleprob, alg, EnsembleThreads(); trajectories = 1000)","category":"section"},{"location":"interfaces/Ensembles/#Solution-Type","page":"Parallel Ensemble Simulations Interface","title":"Solution Type","text":"The resulting type is a EnsembleSimulation, which includes the array of solutions.","category":"section"},{"location":"interfaces/Ensembles/#Plot-Recipe","page":"Parallel Ensemble Simulations Interface","title":"Plot Recipe","text":"There is a plot recipe for a AbstractEnsembleSimulation which composes all of the plot recipes for the component solutions. The keyword arguments are passed along. A useful argument to use is linealpha which will change the transparency of the plots. An additional argument is idxs which allows you to choose which components of the solution to plot. For example, if the differential equation is a vector of 9 values, idxs=1:2:9 will plot only the solutions of the odd components. Another additional argument is zcolors (an alias of marker_z) which allows you to pass a zcolor for each series. For details about zcolor see the Series documentation for Plots.jl.","category":"section"},{"location":"interfaces/Ensembles/#Analyzing-an-Ensemble-Experiment","page":"Parallel Ensemble Simulations Interface","title":"Analyzing an Ensemble Experiment","text":"Analysis tools are included for generating summary statistics and summary plots for a EnsembleSimulation.\n\nTo use this functionality, import the analysis module via:\n\nusing SciMLBase.EnsembleAnalysis","category":"section"},{"location":"interfaces/Ensembles/#Time-steps-vs-time-points","page":"Parallel Ensemble Simulations Interface","title":"Time steps vs time points","text":"For the summary statistics, there are two types. You can either summarize by time steps or by time points. Summarizing by time steps assumes that the time steps are all the same time point, i.e. the integrator used a fixed dt or the values were saved using saveat. Summarizing by time points requires interpolating the solution.","category":"section"},{"location":"interfaces/Ensembles/#Summary-Statistics-Functions","page":"Parallel Ensemble Simulations Interface","title":"Summary Statistics Functions","text":"","category":"section"},{"location":"interfaces/Ensembles/#Single-Time-Statistics","page":"Parallel Ensemble Simulations Interface","title":"Single Time Statistics","text":"The available functions for time steps are:\n\nThe available functions for time points are:","category":"section"},{"location":"interfaces/Ensembles/#Full-Timeseries-Statistics","page":"Parallel Ensemble Simulations Interface","title":"Full Timeseries Statistics","text":"Additionally, the following functions are provided for analyzing the full timeseries. The mean and meanvar versions return a DiffEqArray which can be directly plotted. The meancov and meancor return a matrix of tuples, where the tuples are the (mean_t1,mean_t2,cov or cor).\n\nThe available functions for the time steps are:\n\nThe available functions for the time points are:","category":"section"},{"location":"interfaces/Ensembles/#EnsembleSummary","page":"Parallel Ensemble Simulations Interface","title":"EnsembleSummary","text":"","category":"section"},{"location":"interfaces/Ensembles/#Example-1:-Solving-an-ODE-With-Different-Initial-Conditions","page":"Parallel Ensemble Simulations Interface","title":"Example 1: Solving an ODE With Different Initial Conditions","text":"","category":"section"},{"location":"interfaces/Ensembles/#Random-Initial-Conditions","page":"Parallel Ensemble Simulations Interface","title":"Random Initial Conditions","text":"Let's test the sensitivity of the linear ODE to its initial condition. To do this, we would like to solve the linear ODE 100 times and plot what the trajectories look like. Let's start by opening up some extra processes so that way the computation will be parallelized. Here we will choose to use distributed parallelism, which means that the required functions must be made available to all processes. This can be achieved with @everywhere macro:\n\nusing Distributed\nusing OrdinaryDiffEq\nusing Plots\n\naddprocs()\n@everywhere using OrdinaryDiffEq\n\nNow let's define the linear ODE, which is our base problem:\n\n# Linear ODE which starts at 0.5 and solves from t=0.0 to t=1.0\nprob = ODEProblem((u, p, t) -> 1.01u, 0.5, (0.0, 1.0))\n\nFor our ensemble simulation, we would like to change the initial condition around. This is done through the prob_func. This function takes in the base problem and modifies it to create the new problem that the trajectory actually solves. The prob_func has the signature prob_func(prob, i, repeat) where:\n\nprob is the base problem to be modified\ni is the unique trajectory index (1 to trajectories)  \nrepeat is the repeat iteration number (starts at 1, increments if output_func returned rerun=true)\n\nHere, we will take the base problem, multiply the initial condition by a rand(), and use that for calculating the trajectory:\n\n@everywhere function prob_func(prob, i, repeat)\n    remake(prob, u0 = rand() * prob.u0)\nend\n\nNow we build and solve the EnsembleProblem with this base problem and prob_func:\n\nensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\nsim = solve(ensemble_prob, Tsit5(), EnsembleDistributed(), trajectories = 10)\n\nWe can use the plot recipe to plot what the 10 ODEs look like:\n\nplot(sim, linealpha = 0.4)\n\nWe note that if we wanted to find out what the initial condition was for a given trajectory, we can retrieve it from the solution. sim[i] returns the ith solution object. sim[i].prob is the problem that specific trajectory solved, and sim[i].prob.u0 would then be the initial condition used in the ith trajectory.\n\nNote: If the problem has callbacks, the functions for the condition and affect! must be named functions (not anonymous functions).","category":"section"},{"location":"interfaces/Ensembles/#Using-multithreading","page":"Parallel Ensemble Simulations Interface","title":"Using multithreading","text":"The previous ensemble simulation can also be parallelized using a multithreading approach, which will make use of the different cores within a single computer. Because the memory is shared across the different threads, it is not necessary to use the @everywhere macro. Instead, the same problem can be implemented simply as:\n\nusing OrdinaryDiffEq\nprob = ODEProblem((u, p, t) -> 1.01u, 0.5, (0.0, 1.0))\nfunction prob_func(prob, i, repeat)\n    remake(prob, u0 = rand() * prob.u0)\nend\nensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\nsim = solve(ensemble_prob, Tsit5(), EnsembleThreads(), trajectories = 10)\nusing Plots;\nplot(sim);\n\nThe number of threads to be used has to be defined outside of Julia, in the environmental variable JULIA_NUM_THREADS (see Julia's documentation for details).","category":"section"},{"location":"interfaces/Ensembles/#Pre-Determined-Initial-Conditions","page":"Parallel Ensemble Simulations Interface","title":"Pre-Determined Initial Conditions","text":"Often, you may already know what initial conditions you want to use. This can be specified by the i argument of the prob_func. This i is the unique index of each trajectory. So, if we have trajectories=100, then we have i as some index in 1:100, and it's different for each trajectory.\n\nSo, if we wanted to use a grid of evenly spaced initial conditions from 0 to 1, we could simply index the linspace type:\n\ninitial_conditions = range(0, stop = 1, length = 100)\nfunction prob_func(prob, i, repeat)\n    remake(prob, u0 = initial_conditions[i])\nend\n\nIt's worth noting that if you run this code successfully, there will be no visible output.","category":"section"},{"location":"interfaces/Ensembles/#Example-2:-Solving-an-SDE-with-Different-Parameters","page":"Parallel Ensemble Simulations Interface","title":"Example 2: Solving an SDE with Different Parameters","text":"Let's solve the same SDE, but with varying parameters. Let's create a Lotka-Volterra system with multiplicative noise. Our Lotka-Volterra system will have as its drift component:\n\nfunction f(du, u, p, t)\n    du[1] = p[1] * u[1] - p[2] * u[1] * u[2]\n    du[2] = -3 * u[2] + u[1] * u[2]\nend\n\nFor our noise function, we will use multiplicative noise:\n\nfunction g(du, u, p, t)\n    du[1] = p[3] * u[1]\n    du[2] = p[4] * u[2]\nend\n\nNow we build the SDE with these functions:\n\nusing StochasticDiffEq\np = [1.5, 1.0, 0.1, 0.1]\nprob = SDEProblem(f, g, [1.0, 1.0], (0.0, 10.0), p)\n\nThis is the base problem for our study. What would like to do with this experiment is keep the same parameters in the deterministic component each time, but vary the parameters for the amount of noise using 0.3rand(2) as our parameters. Once again, we do this with a prob_func, and here we modify the parameters in prob.p:\n\n# `p` is a global variable, referencing it would be type unstable.\n# Using a let block defines a small local scope in which we can\n# capture that local `p` which isn't redefined anywhere in that local scope.\n# This allows it to be type stable.\nprob_func = let p = p\n    (prob, i, repeat) -> begin\n        x = 0.3rand(2)\n        remake(prob, p = [p[1], p[2], x[1], x[2]])\n    end\nend\n\nNow we solve the problem 10 times and plot all of the trajectories in phase space:\n\nensemble_prob = EnsembleProblem(prob, prob_func = prob_func)\nsim = solve(ensemble_prob, SRIW1(), trajectories = 10)\nusing Plots;\nplot(sim, linealpha = 0.6, color = :blue, idxs = (0, 1), title = \"Phase Space Plot\");\nplot!(sim, linealpha = 0.6, color = :red, idxs = (0, 2), title = \"Phase Space Plot\")\n\nWe can then summarize this information with the mean/variance bounds using a EnsembleSummary plot. We will take the mean/quantile at every 0.1 time units and directly plot the summary:\n\nsumm = EnsembleSummary(sim, 0:0.1:10)\nplot(summ, fillalpha = 0.5)\n\nNote that here we used the quantile bounds, which default to [0.05,0.95] in the EnsembleSummary constructor. We can change to standard error of the mean bounds using ci_type=:SEM in the plot recipe.","category":"section"},{"location":"interfaces/Ensembles/#Example-3:-Using-the-Reduction-to-Halt-When-Estimator-is-Within-Tolerance","page":"Parallel Ensemble Simulations Interface","title":"Example 3: Using the Reduction to Halt When Estimator is Within Tolerance","text":"In this problem, we will solve the equation just as many times as needed to get the standard error of the mean for the final time point below our tolerance 0.5. Since we only care about the endpoint, we can tell the output_func to discard the rest of the data.\n\nfunction output_func(sol, i)\n    last(sol), false\nend\n\nOur prob_func will simply randomize the initial condition:\n\nusing OrdinaryDiffEq\n# Linear ODE which starts at 0.5 and solves from t=0.0 to t=1.0\nprob = ODEProblem((u, p, t) -> 1.01u, 0.5, (0.0, 1.0))\n\nfunction prob_func(prob, i, repeat)\n    remake(prob, u0 = rand() * prob.u0)\nend\n\nOur reduction function will append the data from the current batch to the previous batch, and declare convergence if the standard error of the mean is calculated as sufficiently small:\n\nusing Statistics\nfunction reduction(u, batch, I)\n    u = append!(u, batch)\n    finished = (var(u) / sqrt(last(I))) / mean(u) < 0.5\n    u, finished\nend\n\nThen we can define and solve the problem:\n\nprob2 = EnsembleProblem(prob, prob_func = prob_func, output_func = output_func,\n    reduction = reduction, u_init = Vector{Float64}())\nsim = solve(prob2, Tsit5(), trajectories = 10000, batch_size = 20)\n\nSince batch_size=20, this means that every 20 simulations, it will take this batch, append the results to the previous batch, calculate (var(u)/sqrt(last(I)))/mean(u), and if that's small enough, exit the simulation. In this case, the simulation exits only after 20 simulations (i.e. after calculating the first batch). This can save a lot of time!\n\nIn addition to saving time by checking convergence, we can save memory by reducing between batches. For example, say we only care about the mean at the end once again. Instead of saving the solution at the end for each trajectory, we can instead save the running summation of the endpoints:\n\nfunction reduction(u, batch, I)\n    u + sum(batch), false\nend\nprob2 = EnsembleProblem(prob, prob_func = prob_func, output_func = output_func,\n    reduction = reduction, u_init = 0.0)\nsim2 = solve(prob2, Tsit5(), trajectories = 100, batch_size = 20)\n\nthis will sum up the endpoints after every 20 solutions, and save the running sum. The final result will have sim2.u as simply a number, and thus sim2.u/100 would be the mean.","category":"section"},{"location":"interfaces/Ensembles/#Example-4:-Using-the-Analysis-Tools","page":"Parallel Ensemble Simulations Interface","title":"Example 4: Using the Analysis Tools","text":"In this example, we will show how to analyze a EnsembleSolution. First, let's generate a 10 solution Monte Carlo experiment. For our problem, we will use a 4x2 system of linear stochastic differential equations:\n\nfunction f(du, u, p, t)\n    for i in 1:length(u)\n        du[i] = 1.01 * u[i]\n    end\nend\nfunction σ(du, u, p, t)\n    for i in 1:length(u)\n        du[i] = 0.87 * u[i]\n    end\nend\nusing StochasticDiffEq\nprob = SDEProblem(f, σ, ones(4, 2) / 2, (0.0, 1.0)) #prob_sde_2Dlinear\n\nTo solve this 10 times, we use the EnsembleProblem constructor and solve with trajectories=10. Since we wish to compare values at the timesteps, we need to make sure the steps all hit the same times. We thus set adaptive=false and explicitly give a dt.\n\nprob2 = EnsembleProblem(prob)\nsim = solve(prob2, SRIW1(), dt = 1 // 2^(3), trajectories = 10, adaptive = false)\n\nNote that if you don't do the timeseries_steps calculations, this code is compatible with adaptive timestepping. Using adaptivity is usually more efficient!\n\nWe can compute the mean and the variance at the 3rd timestep using:\n\nusing SciMLBase.EnsembleAnalysis\nm, v = timestep_meanvar(sim, 3)\n\nor we can compute the mean and the variance at the t=0.5 using:\n\nm, v = timepoint_meanvar(sim, 0.5)\n\nWe can get a series for the mean and the variance at each time step using:\n\nm_series, v_series = timeseries_steps_meanvar(sim)\n\nor at chosen values of t:\n\nts = 0:0.1:1\nm_series = timeseries_point_mean(sim, ts)\n\nNote that these mean and variance series can be directly plotted. We can compute covariance matrices similarly:\n\ntimeseries_steps_meancov(sim) # Use the time steps, assume fixed dt\ntimeseries_point_meancov(sim, 0:(1 // 2 ^ (3)):1, 0:(1 // 2 ^ (3)):1) # Use time points, interpolate\n\nFor general analysis, we can build a EnsembleSummary type.\n\nsumm = EnsembleSummary(sim)\n\nwill summarize at each time step, while\n\nsumm = EnsembleSummary(sim, 0.0:0.1:1.0)\n\nwill summarize at the 0.1 time points using the interpolations. To visualize the results, we can plot it. Since there are 8 components to the differential equation, this can get messy, so let's only plot the 3rd component:\n\nusing Plots;\nplot(summ; idxs = 3);\n\nWe can change to errorbars instead of ribbons and plot two different indices:\n\nplot(summ; idxs = (3, 5), error_style = :bars)\n\nOr we can simply plot the mean of every component over time:\n\nplot(summ; error_style = :none)","category":"section"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleProblem","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleProblem","text":"struct EnsembleProblem{T, T2, T3, T4, T5} <: SciMLBase.AbstractEnsembleProblem\n\nDefines a structure to manage an ensemble (batch) of problems. Each field controls how the ensemble behaves during simulation.\n\nArguments\n\nprob: The original base problem to replicate or modify.\nprob_func: A function that defines how to generate each subproblem.\noutput_func: A function to post-process each individual simulation result.\nreduction: A function to combine results from all simulations.\nu_init: The initial container used to accumulate the results.\nsafetycopy: Whether to copy the problem when creating subproblems (to avoid unintended modifications).\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#SciMLBase.__solve-Tuple{SciMLBase.AbstractEnsembleProblem, Any, SciMLBase.BasicEnsembleAlgorithm}","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.__solve","text":"sim = solve(enprob, alg, ensemblealg = EnsembleThreads(), kwargs...)\n\nSolves the ensemble problem enprob with the algorithm alg using the ensembler ensemblealg.\n\nThe keyword arguments take in the arguments for the common solver interface and will pass them to the solver. The ensemblealg is optional, and will default to EnsembleThreads(). The special keyword arguments to note are:\n\ntrajectories: The number of simulations to run. This argument is required.\nbatch_size : The size of the batches on which the reductions are applies. Defaults to trajectories.\npmap_batch_size: The size of the pmap batches. Default is batch_size÷100 > 0 ? batch_size÷100 : 1\n\n\n\n\n\n","category":"method"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleSerial","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleSerial","text":"struct EnsembleSerial <: SciMLBase.BasicEnsembleAlgorithm\n\nBasic ensemble solver which uses no parallelism and runs the problems in serial\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleThreads","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleThreads","text":"struct EnsembleThreads <: SciMLBase.BasicEnsembleAlgorithm\n\nThe default. This uses multithreading. It's local (single computer, shared memory) parallelism only. Lowest parallelism overhead for small problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleDistributed","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleDistributed","text":"struct EnsembleDistributed <: SciMLBase.BasicEnsembleAlgorithm\n\nUses pmap internally. It will use as many processors as you have Julia processes. To add more processes, use addprocs(n). These processes can be placed onto multiple different machines in order to paralleize across an entire cluster via passwordless SSH. See Julia's documentation for more details.\n\nRecommended for the case when each trajectory calculation isn't “too quick” (at least about a millisecond each?), where the calculations of a given problem allocate memory, or when you have a very large ensemble. This can be true even on a single shared memory system because distributed process use separate garbage collectors and thus can be even faster than EnsembleThreads if the computation is complex enough.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleSplitThreads","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleSplitThreads","text":"struct EnsembleSplitThreads <: SciMLBase.BasicEnsembleAlgorithm\n\nA mixture of distributed computing with threading. The optimal version of this is to have a process on each node of a computer and then multithread on each system. However, this ensembler will simply use the node setup provided by the Julia Distributed processes, and thus it is recommended that you setup the processes in this fashion before using this ensembler. See Julia's Distributed documentation for more information\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.get_timestep","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.get_timestep","text":"get_timestep(sim, i)\n\n\nReturns an iterator of each simulation at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.get_timepoint","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.get_timepoint","text":"get_timepoint(sim, t)\n\n\nReturns an iterator of each simulation at time point t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.componentwise_vectors_timestep","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.componentwise_vectors_timestep","text":"componentwise_vectors_timestep(sim, i)\n\n\nReturns a vector of each simulation at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.componentwise_vectors_timepoint","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.componentwise_vectors_timepoint","text":"componentwise_vectors_timepoint(sim, t)\n\n\nReturns a vector of each simulation at time point t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_mean","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_mean","text":"timestep_mean(sim, i)\n\n\nComputes the mean of each component at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_median","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_median","text":"timestep_median(sim, i)\n\n\nComputes the median of each component at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_quantile","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_quantile","text":"timestep_quantile(sim, q, i)\n\n\nComputes the quantile q of each component at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_meanvar","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_meanvar","text":"timestep_meanvar(sim, i)\n\n\nComputes the mean and variance of each component at time step i\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_meancov","text":"timestep_meancov(sim, i, j)\n\n\nComputes the mean at i and j, and the covariance, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_meancor","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_meancor","text":"timestep_meancor(sim, i, j)\n\n\nComputes the mean at i and j, and the correlation, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timestep_weighted_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timestep_weighted_meancov","text":"timestep_weighted_meancov(sim, W, i, j)\n\n\nComputes the mean at i and j, and the weighted covariance W, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_mean","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_mean","text":"timepoint_mean(sim, t)\n\n\nComputes the mean of each component at time t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_median","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_median","text":"timepoint_median(sim, t)\n\n\nComputes the median of each component at time t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_quantile","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_quantile","text":"timepoint_quantile(sim, q, t)\n\n\nComputes the quantile q of each component at time t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_meanvar","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_meanvar","text":"timepoint_meanvar(sim, t)\n\n\nComputes the mean and variance of each component at time t\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_meancov","text":"timepoint_meancov(sim, t1, t2)\n\n\nComputes the mean at t1 and t2, the covariance, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_meancor","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_meancor","text":"timepoint_meancor(sim, t1, t2)\n\n\nComputes the mean at t1 and t2, the correlation, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timepoint_weighted_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timepoint_weighted_meancov","text":"timepoint_weighted_meancov(sim, W, t1, t2)\n\n\nComputes the mean at t1 and t2, the weighted covariance W, for each component\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_mean","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_mean","text":"timeseries_point_mean(sim, ts)\n\n\nComputes the mean at each time point in ts\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_median","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_median","text":"timeseries_point_median(sim, ts)\n\n\nComputes the median at each time point in ts\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_quantile","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_quantile","text":"timeseries_point_quantile(sim, q, ts)\n\n\nComputes the quantile q at each time point in ts\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_meanvar","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_meanvar","text":"timeseries_point_meanvar(sim, ts)\n\n\nComputes the mean and variance at each time point in ts\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_meancov","text":"timeseries_point_meancov(sim, ts)\n\n\nComputes the covariance matrix and means at each time point in ts\n\n\n\n\n\ntimeseries_point_meancov(sim, ts1, ts2)\n\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_meancor","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_meancor","text":"timeseries_point_meancor(sim, ts)\n\n\nComputes the correlation matrix and means at each time point in ts\n\n\n\n\n\ntimeseries_point_meancor(sim, ts1, ts2)\n\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleAnalysis.timeseries_point_weighted_meancov","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleAnalysis.timeseries_point_weighted_meancov","text":"timeseries_point_weighted_meancov(sim, W, ts)\n\n\nComputes the weighted covariance matrix and means at each time point in ts\n\n\n\n\n\ntimeseries_point_weighted_meancov(sim, W, ts1, ts2)\n\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Ensembles/#SciMLBase.EnsembleSummary","page":"Parallel Ensemble Simulations Interface","title":"SciMLBase.EnsembleSummary","text":"struct EnsembleSummary{T, N, Tt, S, S2, S3, S4, S5} <: SciMLBase.AbstractEnsembleSolution{T, N, S}\n\nThe EnsembleSummary type is included to help with analyzing the general summary statistics. Two constructors are provided:\n\nEnsembleSummary(sim; quantiles = [0.05, 0.95])\nEnsembleSummary(sim, ts; quantiles = [0.05, 0.95])\n\nThe first produces a (mean,var) summary at each time step. As with the summary statistics, this assumes that the time steps are all the same. The second produces a (mean,var) summary at each time point t in ts. This requires the ability to interpolate the solution. Quantile is used to determine the qlow and qhigh quantiles at each timepoint. It defaults to the 5% and 95% quantiles.\n\nPlot Recipe\n\nThe EnsembleSummary comes with a plot recipe for visualizing the summary statistics. The extra keyword arguments are:\n\nidxs: the solution components to plot. Defaults to plotting all components.\nerror_style: The style for plotting the error. Defaults to ribbon. Other choices are :bars for error bars and :none for no error bars.\nci_type : Defaults to :quantile which has (qlow,qhigh) quantiles whose limits were determined when constructing the EnsembleSummary. Gaussian CI 1.96*(standard error of the mean) can be set using ci_type=:SEM.\n\nOne useful argument is fillalpha which controls the transparency of the ribbon around the mean.\n\n\n\n\n\n","category":"type"},{"location":"fundamentals/FAQ/#Frequently-Asked-Questions","page":"Frequently Asked Questions","title":"Frequently Asked Questions","text":"","category":"section"},{"location":"fundamentals/FAQ/#What-are-the-code-styling-rules-for-SciML?","page":"Frequently Asked Questions","title":"What are the code styling rules for SciML?","text":"All SciML libraries are supposed to follow SciMLStyle. Any deviation from that style is something to be fixed.","category":"section"},{"location":"fundamentals/FAQ/#Where-do-I-find-more-information-on-the-internals-of-some-packages?","page":"Frequently Asked Questions","title":"Where do I find more information on the internals of some packages?","text":"The SciML Developer Documentation describes the internals of some of the larger solver libraries at length.","category":"section"},{"location":"fundamentals/FAQ/#What-are-the-community-practices-that-SciML-developers-should-use?","page":"Frequently Asked Questions","title":"What are the community practices that SciML developers should use?","text":"See ColPrac: Contributor's Guide on Collaborative Practices for Community Packages","category":"section"},{"location":"fundamentals/FAQ/#Are-there-developer-programs-to-help-fund-parties-interested-in-helping-develop-SciML?","page":"Frequently Asked Questions","title":"Are there developer programs to help fund parties interested in helping develop SciML?","text":"Yes! See the SciML Developer Programs webpage.","category":"section"},{"location":"interfaces/Problems/#scimlproblems","page":"SciMLProblems","title":"SciMLProblems","text":"The cornerstone of the SciML common interface is the problem type definition. These definitions are the encoding of mathematical problems into a numerically computable form.","category":"section"},{"location":"interfaces/Problems/#Note-About-Symbolics-and-ModelingToolkit","page":"SciMLProblems","title":"Note About Symbolics and ModelingToolkit","text":"The symbolic analog to the problem interface is the ModelingToolkit AbstractSystem. For example, ODESystem is the symbolic analog to ODEProblem. Each of these system types have a method for constructing the associated problem and function types.","category":"section"},{"location":"interfaces/Problems/#Definition-of-the-AbstractSciMLProblem-Interface","page":"SciMLProblems","title":"Definition of the AbstractSciMLProblem Interface","text":"The following standard principles should be adhered to across all AbstractSciMLProblem instantiations.","category":"section"},{"location":"interfaces/Problems/#In-place-Specification","page":"SciMLProblems","title":"In-place Specification","text":"Each AbstractSciMLProblem type can be called with an \"is inplace\" (iip) choice. For example:\n\nODEProblem(f, u0, tspan, p)\nODEProblem{iip}(f, u0, tspan, p)\n\nwhich is a boolean for whether the function is in the inplace form (mutating to change the first value). This is automatically determined using the methods table but note that for full type-inferability of the AbstractSciMLProblem this iip-ness should be specified.\n\nAdditionally, the functions are fully specialized to reduce the runtimes. If one would instead like to not specialize on the functions to reduce compile time, then one can set recompile to false.","category":"section"},{"location":"interfaces/Problems/#Specialization-Levels","page":"SciMLProblems","title":"Specialization Levels","text":"Specialization levels in problem definitions are used to control the amount of compilation specialization is performed on the model functions in order to trade off between runtime performance, simplicity, and compile-time performance. The default choice of specialization is AutoSpecialize, which seeks to allow for using fully precompiled solvers in common scenarios but falls back to a runtime-optimal approach when further customization is used.\n\nSpecialization levels are given as the second type parameter in AbstractSciMLProblem constructors. For example, this is done via:\n\nODEProblem{iip, specialization}(f, u0, tspan, p)\n\nNote that iip choice is required for specialization choices to be made.","category":"section"},{"location":"interfaces/Problems/#Specialization-Choices","page":"SciMLProblems","title":"Specialization Choices","text":"note: Note\nThe specialization level must be precompile snooped in the appropriate solver package in order to enable the full precompilation and system image generation for zero-latency usage. By default, this is only done with AutoSpecialize and on types u isa Vector{Float64}, eltype(tspan) isa Float64, and p isa Union{Vector{Float64}, SciMLBase.NullParameters}. Precompilation snooping in the solvers can be done using the Preferences.jl setup on the appropriate solver. See the solver library's documentation for more details.","category":"section"},{"location":"interfaces/Problems/#Default-Parameters","page":"SciMLProblems","title":"Default Parameters","text":"By default, AbstractSciMLProblem types use the SciMLBase.NullParameters() singleton to define the absence of parameters by default. The reason is because this throws an informative error if the parameter is used or accessed within the user's function, for example, p[1] will throw an informative error about forgetting to pass parameters.","category":"section"},{"location":"interfaces/Problems/#Keyword-Argument-Splatting","page":"SciMLProblems","title":"Keyword Argument Splatting","text":"All AbstractSciMLProblem types allow for passing keyword arguments that would get forwarded to the solver. The reason for this is that in many cases, like in EnsembleProblem usage, a AbstractSciMLProblem might be associated with some solver configuration, such as a callback or tolerance. Thus, for flexibility the extra keyword arguments to the AbstractSciMLProblem are carried to the solver.","category":"section"},{"location":"interfaces/Problems/#problem_type","page":"SciMLProblems","title":"problem_type","text":"AbstractSciMLProblem types include a non-public API definition of problem_type which holds a trait type corresponding to the way the AbstractSciMLProblem was constructed. For example, if a SecondOrderODEProblem constructor is used, the returned problem is simply a ODEProblem for interoperability with any ODEProblem algorithm. However, in this case the problem_type will be populated with the SecondOrderODEProblem type, indicating the original definition and extra structure.","category":"section"},{"location":"interfaces/Problems/#Remake","page":"SciMLProblems","title":"Remake","text":"For problems that are created from a system (e.g. created through ModelingToolkit.jl) or define a DSL using SymbolicIndexingInterface.SymbolCache, remake can accept symbolic maps as u0 or p. A symbolic map is a Dict or Vector{<:Pair} mapping symbols in u0 or p to their values. These values can be numeric, or expressions of other symbols. Symbolic maps can be complete (specifying a value for each symbol in u0 or p) or partial. For a partial symbolic map, the values of remaining symbols are obtained through the system's defaults (see SymbolicIndexingInterface.default_values) and the existing values in the problem passed to remake.\n\nIf the system's defaults contain an expression for the missing symbol, that expression will be used for the value (it is treated as a dependent initialization). Otherwise, the existing value of that symbol in the problem passed to remake is used.\n\nIf default_values = true is passed as a keyword argument to remake, then the value contained in the system's defaults is always preferred over the value in the problem.\n\nFor example, consider a problem prob with parameters :a, :b, :c having values 1.0, 2.0, 3.0 respectively. Let us also assume that the system contains the defaults Dict(:a => :(2b), :c => 0.1). Then:\n\nremake(prob; p = [:b => 2.0]) will result in the values 4.0, 2.0, 3.0 for :a, :b and :c respectively. Note how the numeric default for :c was not respected.\nremake(prob; p = [:b => 2.0], use_defaults = true) will result in the values 4.0, 2.0, 1.0 for :a, :b and :c respectively.\nremake(prob; p = [:b => 2.0, :a => 3.0]) will result in the values 3.0, 2.0, 3.0 for :a, :b and :c respectively. Note how the explicitly specified value for :a overrides the dependent default.","category":"section"},{"location":"interfaces/Problems/#Aliasing-Specification","page":"SciMLProblems","title":"Aliasing Specification","text":"An AbstractAliasSpecifier is associated with each SciMLProblem type. Each holds fields specifying which variables to alias when solving. For example, to tell an ODE solver to alias the u0 array, you can use an ODEAliases object, and the alias_u0 keyword argument, e.g. solve(prob,alias = ODEAliases(alias_u0 = true)).","category":"section"},{"location":"interfaces/Problems/#Problem-Traits","page":"SciMLProblems","title":"Problem Traits","text":"","category":"section"},{"location":"interfaces/Problems/#AbstractSciMLProblem-API","page":"SciMLProblems","title":"AbstractSciMLProblem API","text":"","category":"section"},{"location":"interfaces/Problems/#Defaults-and-Preferences","page":"SciMLProblems","title":"Defaults and Preferences","text":"SpecializationLevel at SciMLBase can be used to set the default specialization level. The following shows how to set the specialization default to FullSpecialize:\n\nusing Preferences, UUIDs\nset_preferences!(\n    UUID(\"0bca4576-84f4-4d90-8ffe-ffa030f20462\"), \"SpecializationLevel\" => \"FullSpecialize\")\n\nThe default is AutoSpecialize.","category":"section"},{"location":"interfaces/Problems/#Abstract-SciMLProblems","page":"SciMLProblems","title":"Abstract SciMLProblems","text":"","category":"section"},{"location":"interfaces/Problems/#SciMLBase.AbstractSpecialization","page":"SciMLProblems","title":"SciMLBase.AbstractSpecialization","text":"abstract type AbstractSpecialization\n\nSupertype for the specialization types. Controls the compilation and function specialization behavior of SciMLFunctions, ultimately controlling the runtime vs compile-time trade-off.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AutoSpecialize","page":"SciMLProblems","title":"SciMLBase.AutoSpecialize","text":"struct AutoSpecialize <: SciMLBase.AbstractSpecialization\n\nThe default specialization level for problem functions. AutoSpecialize works by applying a function wrap just-in-time before the solve process to disable just-in-time re-specialization of the solver to the specific choice of model f and thus allow for using a cached solver compilation from a different f. This wrapping process can lead to a small decreased runtime performance with a benefit of a greatly decreased compile-time.\n\nNote About Benchmarking and Runtime Optimality\n\nIt is recommended that AutoSpecialize is not used in any benchmarking due to the potential effect of function wrapping on runtimes. AutoSpecialize's use case is targeted at decreased latency for REPL performance and not for cases where where top runtime performance is required (such as in optimization loops). Generally, for non-stiff equations the cost will be minimal and potentially not even measurable. For stiff equations, function wrapping has the limitation that only chunk sized 1 Dual numbers are allowed, which can decrease Jacobian construction performance.\n\nLimitations of AutoSpecialize\n\nThe following limitations are not fundamental to the implementation of AutoSpecialize, but are instead chosen as a compromise between default precompilation times and ease of maintenance. Please open an issue to discuss lifting any potential limitations.\n\nAutoSpecialize is only setup to wrap the functions from in-place ODEs. Other cases are excluded for the time being due to time limitations.\nAutoSpecialize will only lead to compilation reuse if the ODEFunction's other functions (such as jac and tgrad) are the default nothing. These could be JIT wrapped as well in a future version.\nAutoSpecialize'd functions are only compatible with Jacobian calculations performed with chunk size 1, and only with tag DiffEqBase.OrdinaryDiffEqTag(). Thus ODE solvers written on the common interface must be careful to detect the AutoSpecialize case and perform differentiation under these constraints, use finite differencing, or manually unwrap before solving. This will lead to decreased runtime performance for sufficiently large Jacobians.\nAutoSpecialize only wraps on Julia v1.8 and higher.\nAutoSpecialize does not handle cases with units. If unitful values are detected, wrapping is automatically disabled.\nAutoSpecialize only wraps cases for which promote_rule is defined between u0 and dual numbers, u0 and t, and for which ArrayInterface.promote_eltype is defined on u0 to dual numbers.\nAutoSpecialize only wraps cases for which f.mass_matrix isa UniformScaling, the default.\nAutoSpecialize does not wrap cases where f isa AbstractSciMLOperator\nBy default, only the u0 isa Vector{Float64}, eltype(tspan) isa Float64, and typeof(p) isa Union{Vector{Float64},SciMLBase.NullParameters} are specialized by the solver libraries. Other forms can be specialized with AutoSpecialize, but must be done in the precompilation of downstream libraries.\nAutoSpecialized functions are manually unwrapped in adjoint methods in SciMLSensitivity.jl in order to allow compiler support for automatic differentiation. Improved versions of adjoints which decrease the recompilation surface will come in non-breaking updates.\n\nCases where automatic wrapping is disabled are equivalent to FullSpecialize.\n\nExample\n\nf(du, u, p, t) = (du .= u)\n\n# Note this is the same as ODEProblem(f, [1.0], (0.0,1.0))\n# If no preferences are set\nODEProblem{true, SciMLBase.AutoSpecialize}(f, [1.0], (0.0, 1.0))\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.NoSpecialize","page":"SciMLProblems","title":"SciMLBase.NoSpecialize","text":"struct NoSpecialize <: SciMLBase.AbstractSpecialization\n\nNoSpecialize forces SciMLFunctions to not specialize on the types of functions wrapped within it. This ultimately contributes to a form such that every prob.f type is the same, meaning compilation caches are fully reused, with the downside of losing runtime performance. NoSpecialize is the form that most fully trades off runtime for compile time. Unlike AutoSpecialize, NoSpecialize can be used with any SciMLFunction.\n\nExample\n\nf(du, u, p, t) = (du .= u)\nODEProblem{true, SciMLBase.NoSpecialize}(f, [1.0], (0.0, 1.0))\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.FunctionWrapperSpecialize","page":"SciMLProblems","title":"SciMLBase.FunctionWrapperSpecialize","text":"struct FunctionWrapperSpecialize <: SciMLBase.AbstractSpecialization\n\nFunctionWrapperSpecialize is an eager wrapping choice which performs a function wrapping during the ODEProblem construction. This performs the function wrapping at the earliest possible point, giving the best compile-time vs runtime performance, but with the difficulty that any usage of prob.f needs to account for the function wrapper's presence. While optimal in a performance sense, this method has many usability issues with nonstandard solvers and analyses as it requires unwrapping before re-wrapping for any type changes. Thus this method is not used by default. Given that the compile-time different is almost undetectable from AutoSpecialize, this method is mostly used as a benchmarking reference for speed of light for AutoSpecialize.\n\nLimitations of FunctionWrapperSpecialize\n\nFunctionWrapperSpecialize has all of the limitations of AutoSpecialize, but also includes the limitations:\n\nprob.f is directly specialized to the types of (u,p,t), and any usage of prob.f on other types first requires using SciMLBase.unwrapped_f(prob.f) to remove the function wrapper.\nFunctionWrapperSpecialize can only be used by the ODEProblem constructor. If an ODEFunction is being constructed, the user must manually use DiffEqBase.wrap_iip on f before calling ODEFunction{true,FunctionWrapperSpecialize}(f). This is a fundamental limitation of the approach as the types of (u,p,t) are required in the construction process and not accessible in the AbstractSciMLFunction constructors.\n\nExample\n\nf(du, u, p, t) = (du .= u)\nODEProblem{true, SciMLBase.FunctionWrapperSpecialize}(f, [1.0], (0.0, 1.0))\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.FullSpecialize","page":"SciMLProblems","title":"SciMLBase.FullSpecialize","text":"struct FullSpecialize <: SciMLBase.AbstractSpecialization\n\nFullSpecialize is an eager specialization choice which directly types the AbstractSciMLFunction struct to match the type of the model f. This forces recompilation of the solver on each new function type f, leading to the most compile times with the benefit of having the best runtime performance.\n\nFullSpecialize should be used in all cases where top runtime performance is required, such as in long-running simulations and benchmarking.\n\nExample\n\nf(du, u, p, t) = (du .= u)\nODEProblem{true, SciMLBase.FullSpecialize}(f, [1.0], (0.0, 1.0))\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.remake","page":"SciMLProblems","title":"SciMLBase.remake","text":"remake(thing; <keyword arguments>)\n\nRe-construct thing with new field values specified by the keyword arguments.\n\n\n\n\n\nremake(prob::AbstractSciMLProblem; u0 = missing, p = missing, interpret_symbolicmap = true, use_defaults = false)\n\nRemake the given problem prob. If u0 or p are given, they will be used instead of the unknowns/parameters of the problem. Either of them can be a symbolic map if the problem has an associated system. If interpret_symbolicmap == false, p will never be interpreted as a symbolic map and used as-is for parameters. use_defaults allows controlling whether the default values from the system will be used to calculate missing values in the symbolic map passed to u0 or p. It is only valid when either u0 or p have been explicitly provided as a symbolic map and the problem has an associated system.\n\n\n\n\n\nremake(func::AbstractSciMLFunction; f = missing, g = missing, f2 = missing, kwargs...)\n\nremake the given func. Return an AbstractSciMLFunction of the same kind, isinplace and specialization as func. Retain the properties of func, except those that are overridden by keyword arguments. For stochastic functions (e.g. SDEFunction) the g keyword argument is used to override func.g. For split functions (e.g. SplitFunction) the f2 keyword argument is used to override func.f2, and f is used for func.f1. If f isa AbstractSciMLFunction and func is not a split function, properties of f will override those of func (but not ones provided via keyword arguments). Properties of f that are nothing will fall back to those in func (unless provided via keyword arguments). If f is a different type of AbstractSciMLFunction from func, the returned function will be of the kind of f unless func is a split function. If func is a split function, f and f2 will be wrapped in the appropriate AbstractSciMLFunction type with the same isinplace and specialization as func.\n\n\n\n\n\nremake(prob::ODEProblem; f = missing, u0 = missing, tspan = missing,\n       p = missing, kwargs = missing, _kwargs...)\n\nRemake the given ODEProblem. If u0 or p are given as symbolic maps ModelingToolkit.jl has to be loaded.\n\n\n\n\n\nremake(prob::BVProblem; f = missing, u0 = missing, tspan = missing,\n       p = missing, kwargs = missing, problem_type = missing, _kwargs...)\n\nRemake the given BVProblem.\n\n\n\n\n\nremake(prob::SDEProblem; f = missing, g = missing, u0 = missing, tspan = missing,\n       p = missing, noise = missing, noise_rate_prototype = missing,\n       seed = missing, kwargs = missing, _kwargs...)\n\nRemake the given SDEProblem.\n\n\n\n\n\nremake(prob::DAEProblem; f = missing, du0 = missing, u0 = missing, tspan = missing,\n       p = missing, differential_vars = missing, kwargs = missing, _kwargs...)\n\nRemake the given DAEProblem. If u0 or p are given as symbolic maps ModelingToolkit.jl has to be loaded.\n\n\n\n\n\nremake(prob::OptimizationProblem; f = missing, u0 = missing, p = missing,\n    lb = missing, ub = missing, int = missing, lcons = missing, ucons = missing,\n    sense = missing, kwargs = missing, _kwargs...)\n\nRemake the given OptimizationProblem. If u0 or p are given as symbolic maps ModelingToolkit.jl has to be loaded.\n\n\n\n\n\nremake(prob::NonlinearProblem; f = missing, u0 = missing, p = missing,\n    problem_type = missing, kwargs = missing, _kwargs...)\n\nRemake the given NonlinearProblem. If u0 or p are given as symbolic maps ModelingToolkit.jl has to be loaded.\n\n\n\n\n\nremake(prob::NonlinearLeastSquaresProblem; f = missing, u0 = missing, p = missing,\n    kwargs = missing, _kwargs...)\n\nRemake the given NonlinearLeastSquaresProblem.\n\n\n\n\n\nremake(prob::SCCNonlinearProblem; u0 = missing, p = missing, probs = missing,\n    parameters_alias = prob.parameters_alias, sys = missing, explicitfuns! = missing)\n\nRemake the given SCCNonlinearProblem. u0 is the state vector for the entire problem, which will be chunked appropriately and used to remake the individual subproblems. p is the parameter object for prob. If parameters_alias, the same parameter object will be used to remake the individual subproblems. Otherwise if p !== missing, this function will error and require that probs be specified. probs is the collection of subproblems. Even if probs is explicitly specified, the value of u0 provided to remake will be used to override the values in probs. sys is the index provider for the full system.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Problems/#SciMLBase.AbstractAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.AbstractAliasSpecifier","text":"abstract type AbstractAliasSpecifier\n\nUsed to specify which variables can be aliased in a solve. Every concrete AbstractAliasSpecifier should have at least the fields alias_p and alias_f.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.LinearAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.LinearAliasSpecifier","text":"LinearAliasSpecifier(; alias_A = nothing, alias_b = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving a LinearProblem. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_A::Union{Bool, Nothing}: alias the A array.\nalias_b::Union{Bool, Nothing}: alias the b array. \nalias::Union{Bool, Nothing}: sets all fields of the LinearAliasSpecifier to alias. \n\nCreates a LinearAliasSpecifier where alias_A and alias_b default to nothing. When alias_A or alias_b is nothing, the default value of the solver is used.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.NonlinearAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.NonlinearAliasSpecifier","text":"NonlinearAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving a NonlinearProblem.  Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array.\nalias::Union{Bool, Nothing}: sets all fields of the NonlinearAliasSpecifier to alias. \n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.ODEAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.ODEAliasSpecifier","text":"ODEAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = false, alias_du0 = false, alias_tstops = false, alias = nothing)\n\nHolds information on what variables to alias when solving an ODE. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false .\nalias_du0::Union{Bool, Nothing}: alias the du0 array for DAEs. Defaults to false.\nalias_tstops::Union{Bool, Nothing}: alias the tstops array\nalias::Union{Bool, Nothing}: sets all fields of the ODEAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.SDEAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.SDEAliasSpecifier","text":"SDEAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias_tstops = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving an SDEProblem. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false.\nalias_tstops::Union{Bool, Nothing}: alias the tstops array\nalias_jumps::Union{Bool, Nothing}: alias jump process if wrapped in a JumpProcess.\nalias::Union{Bool, Nothing}: sets all fields of the SDEAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.DDEAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.DDEAliasSpecifier","text":"DDEAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias_du0 = nothing, alias_tstops = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving a DDE. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false .\nalias_du0::Union{Bool, Nothing}: alias the du0 array for DAEs. Defaults to false.\nalias_tstops::Union{Bool, Nothing}: alias the tstops array\nalias::Union{Bool, Nothing}: sets all fields of the DDEAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.SDDEAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.SDDEAliasSpecifier","text":"SDDEAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias_du0 = nothing, alias_tstops = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving an SDDEProblem. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false.\nalias_tstops::Union{Bool, Nothing}: alias the tstops array\nalias_jumps::Union{Bool, Nothing}: alias jump process if wrapped in a JumpProcess\nalias::Union{Bool, Nothing}: sets all fields of the SDDEAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.BVPAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.BVPAliasSpecifier","text":"BVPAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias_du0 = nothing, alias_tstops = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving an BVP. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false .\nalias_du0::Union{Bool, Nothing}: alias the du0 array for DAEs. Defaults to false.\nalias_tstops::Union{Bool, Nothing}: alias the tstops array\nalias::Union{Bool, Nothing}: sets all fields of the BVPAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.OptimizationAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.OptimizationAliasSpecifier","text":"OptimizationAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = false, alias = nothing)\n\nHolds information on what variables to alias when solving an OptimizationProblem. Conforms to the AbstractAliasSpecifier interface. \n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false .\nalias::Union{Bool, Nothing}: sets all fields of the OptimizationAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.IntegralAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.IntegralAliasSpecifier","text":"IntegralAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving an IntegralProblem. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias::Union{Bool, Nothing}: sets all fields of the IntegralAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.DiscreteAliasSpecifier","page":"SciMLProblems","title":"SciMLBase.DiscreteAliasSpecifier","text":"DiscreteAliasSpecifier(;alias_p = nothing, alias_f = nothing, alias_u0 = nothing, alias = nothing)\n\nHolds information on what variables to alias when solving a DiscreteProblem. Conforms to the AbstractAliasSpecifier interface. \n\nWhen a keyword argument is nothing, the default behaviour of the solver is used.\n\nKeywords\n\nalias_p::Union{Bool, Nothing}\nalias_f::Union{Bool, Nothing}\nalias_u0::Union{Bool, Nothing}: alias the u0 array. Defaults to false .\nalias::Union{Bool, Nothing}: sets all fields of the DiscreteAliasSpecifier to alias\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.isinplace-Tuple{SciMLBase.AbstractDEProblem}","page":"SciMLProblems","title":"SciMLBase.isinplace","text":"isinplace(prob::AbstractSciMLProblem)\n\nDetermine whether the function of the given problem operates in place or not.\n\n\n\n\n\n","category":"method"},{"location":"interfaces/Problems/#SciMLBase.is_diagonal_noise","page":"SciMLProblems","title":"SciMLBase.is_diagonal_noise","text":"is_diagonal_noise(prob::AbstractSciMLProblem)\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Problems/#SciMLBase.AbstractSciMLProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSciMLProblem","text":"abstract type AbstractSciMLProblem\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDEProblem","text":"abstract type AbstractDEProblem <: SciMLBase.AbstractSciMLProblem\n\nBase type for all DifferentialEquations.jl problems. Concrete subtypes of AbstractDEProblem contain the necessary information to fully define a differential equation of the corresponding type.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractLinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractLinearProblem","text":"abstract type AbstractLinearProblem{bType, isinplace} <: SciMLBase.AbstractSciMLProblem\n\nBase for types which define linear systems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractNonlinearProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNonlinearProblem","text":"abstract type AbstractNonlinearProblem{uType, isinplace} <: SciMLBase.AbstractSciMLProblem\n\nBase for types which define nonlinear solve problems (f(u)=0).\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractIntegralProblem","page":"SciMLProblems","title":"SciMLBase.AbstractIntegralProblem","text":"abstract type AbstractIntegralProblem{isinplace} <: SciMLBase.AbstractSciMLProblem\n\nBase for types which define integrals suitable for quadrature.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractOptimizationProblem","page":"SciMLProblems","title":"SciMLBase.AbstractOptimizationProblem","text":"abstract type AbstractOptimizationProblem{isinplace} <: SciMLBase.AbstractSciMLProblem\n\nBase for types which define equations for optimization.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractNoiseProblem","page":"SciMLProblems","title":"SciMLBase.AbstractNoiseProblem","text":"abstract type AbstractNoiseProblem <: SciMLBase.AbstractDEProblem\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractODEProblem","text":"abstract type AbstractODEProblem{uType, tType, isinplace} <: SciMLBase.AbstractDEProblem\n\nBase for types which define ODE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractDiscreteProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDiscreteProblem","text":"abstract type AbstractDiscreteProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define discrete problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractAnalyticalProblem","page":"SciMLProblems","title":"SciMLBase.AbstractAnalyticalProblem","text":"abstract type AbstractAnalyticalProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractRODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractRODEProblem","text":"abstract type AbstractRODEProblem{uType, tType, isinplace, ND} <: SciMLBase.AbstractDEProblem\n\nBase for types which define RODE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractSDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDEProblem","text":"abstract type AbstractSDEProblem{uType, tType, isinplace, ND} <: SciMLBase.AbstractRODEProblem{uType, tType, isinplace, ND}\n\nBase for types which define SDE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractDAEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDAEProblem","text":"abstract type AbstractDAEProblem{uType, duType, tType, isinplace} <: SciMLBase.AbstractDEProblem\n\nBase for types which define DAE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractDDEProblem","text":"abstract type AbstractDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.AbstractDEProblem\n\nBase for types which define DDE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractConstantLagDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagDDEProblem","text":"abstract type AbstractConstantLagDDEProblem{uType, tType, lType, isinplace} <: SciMLBase.AbstractDDEProblem{uType, tType, lType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractSecondOrderODEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSecondOrderODEProblem","text":"abstract type AbstractSecondOrderODEProblem{uType, tType, isinplace} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractBVProblem","page":"SciMLProblems","title":"SciMLBase.AbstractBVProblem","text":"abstract type AbstractBVProblem{uType, tType, isinplace, nlls} <: SciMLBase.AbstractODEProblem{uType, tType, isinplace}\n\nBase for types which define BVP problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractJumpProblem","page":"SciMLProblems","title":"SciMLBase.AbstractJumpProblem","text":"abstract type AbstractJumpProblem{P, J} <: SciMLBase.AbstractDEProblem\n\nBase for types which define jump problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractSDDEProblem","text":"abstract type AbstractSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.AbstractDEProblem\n\nBase for types which define SDDE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractConstantLagSDDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractConstantLagSDDEProblem","text":"abstract type AbstractConstantLagSDDEProblem{uType, tType, lType, isinplace, ND} <: SciMLBase.AbstractSDDEProblem{uType, tType, lType, isinplace, ND}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Problems/#SciMLBase.AbstractPDEProblem","page":"SciMLProblems","title":"SciMLBase.AbstractPDEProblem","text":"abstract type AbstractPDEProblem <: SciMLBase.AbstractDEProblem\n\nBase for types which define PDE problems.\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLSolutions","page":"SciMLSolutions","title":"SciMLSolutions","text":"","category":"section"},{"location":"interfaces/Solutions/#Definition-of-the-AbstractSciMLSolution-Interface","page":"SciMLSolutions","title":"Definition of the AbstractSciMLSolution Interface","text":"All AbstractSciMLSolution types are a subset of some AbstractArray. Types with time series (like ODESolution) are subtypes of RecursiveArrayTools.AbstractVectorOfArray and RecursiveArrayTools.AbstractDiffEqArray where appropriate. Types without a time series (like OptimizationSolution) are directly subsets of AbstractArray.","category":"section"},{"location":"interfaces/Solutions/#Array-Interface","page":"SciMLSolutions","title":"Array Interface","text":"Instead of working on the Vector{uType} directly, we can use the provided array interface.\n\nsol[j]\n\nto access the value at timestep j (if the timeseries was saved), and\n\nsol.t[j]\n\nto access the value of t at timestep j. For multi-dimensional systems, this will address first by component and lastly by time, and thus\n\nsol[i, j]\n\nwill be the ith component at timestep j. Hence, sol[j][i] == sol[i, j]. This is done because Julia is column-major, so the leading dimension should be contiguous in memory. If the independent variables had shape (for example, was a matrix), then i is the linear index. We can also access solutions with shape:\n\nsol[i, k, j]\n\ngives the [i,k] component of the system at timestep j. The colon operator is supported, meaning that\n\nsol[i, :]\n\ngives the timeseries for the ith component.","category":"section"},{"location":"interfaces/Solutions/#Common-Field-Names","page":"SciMLSolutions","title":"Common Field Names","text":"u: the solution values\nt: the independent variable values, matching the length of the solution, if applicable\nresid: the residual of the solution, if applicable\noriginal: the solution object from the original solver, if it's a wrapper algorithm\nretcode: see the documentation section on return codes\nprob: the problem that was solved\nalg: the algorithm used to solve the problem","category":"section"},{"location":"interfaces/Solutions/#retcodes","page":"SciMLSolutions","title":"Return Codes (RetCodes)","text":"The solution types have a retcode field which returns a SciMLBase.ReturnCode.T (from EnumX.jl, see that package for the semantics of handling EnumX types) signifying the error or satisfaction state of the solution.","category":"section"},{"location":"interfaces/Solutions/#Return-Code-Traits","page":"SciMLSolutions","title":"Return Code Traits","text":"","category":"section"},{"location":"interfaces/Solutions/#Specific-Return-Codes","page":"SciMLSolutions","title":"Specific Return Codes","text":"","category":"section"},{"location":"interfaces/Solutions/#Solution-Traits","page":"SciMLSolutions","title":"Solution Traits","text":"","category":"section"},{"location":"interfaces/Solutions/#AbstractSciMLSolution-API","page":"SciMLSolutions","title":"AbstractSciMLSolution API","text":"","category":"section"},{"location":"interfaces/Solutions/#Abstract-SciML-Solutions","page":"SciMLSolutions","title":"Abstract SciML Solutions","text":"","category":"section"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode","page":"SciMLSolutions","title":"SciMLBase.ReturnCode","text":"SciML.ReturnCode\n\nSciML.ReturnCode is the standard return code enum interface for the SciML interface. Return codes are notes given by the solvers to indicate the state of the solution, for example whether it successfully solved the equations, whether it failed to solve the equations, and importantly, why it exited.\n\nUsing SciML.ReturnCode\n\nSciML.ReturnCode use the interface of EnumX.jl and thus inherits all of the behaviors of being an EnumX. This includes the Enum type itself being referred to as SciML.ReturnCode.T, and each of the constituent enum states being referred to via getproperty, i.e. SciML.ReturnCode.Success.\n\nNote About Success Checking\n\nPrevious iterations of the interface suggested using sol.retcode == :Success, however, that is now not advised instead should be replaced with SciMLBase.successful_retcode(sol). The reason is that there are many different codes that can be interpreted as successful, such as ReturnCode.Terminated which means successfully used terminate!(integrator) to end an integration at a user-specified condition. As such, successful_retcode is the most general way to query for if the solver did not error.\n\nProperties\n\nsuccessful_retcode(retcode::ReturnCode.T): Determines whether the output enum is considered a success state of the solver, i.e. the solver successfully solved the equations. ReturnCode.Success is the most basic form, simply declaring that it was successful, but many more informative success return codes exist as well.\n\n\n\n\n\n","category":"module"},{"location":"interfaces/Solutions/#SciMLBase.successful_retcode","page":"SciMLSolutions","title":"SciMLBase.successful_retcode","text":"successful_retcode(retcode::ReturnCode.T)::Bool\nsuccessful_retcode(sol::AbstractSciMLSolution)::Bool\n\nReturns a boolean for whether a return code should be interpreted as a form of success.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Default","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Default","text":"ReturnCode.Default\n\nThe default state of the solver. If this return code is given, then the solving process is either still in process or the solver library has not been setup with the return code interface and thus the return code is undetermined.\n\nCommon Reasons for Seeing this Return Code\n\nA common reason for Default return codes is that a solver is a non-SciML solver which does not fully conform to the interface. Please open an issue if this is seen and it will be improved.\nAnother common reason for a Default return code is if the solver is probed internally before the solving process is done, such as through the callback interface. Return codes are set to Default to start and are changed to Success and other return codes upon finishing the solving process or hitting a numerical difficulty.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Success","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Success","text":"ReturnCode.Success\n\nThe success state of the solver. If this return code is given, then the solving process was successful, but no extra information about that success is given.\n\nCommon Reasons for Seeing this Return Code\n\nThis is the most common return code and most solvers will give this return code if the solving process went as expected without any errors or detected numerical issues.\n\nProperties\n\nsuccessful_retcode = true\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Terminated","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Terminated","text":"ReturnCode.Terminated\n\nThe successful termination state of the solver. If this return code is given, then the solving process was successful at terminating the solve, usually through a callback affect! via terminate!(integrator).\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is if a user calls a callback which uses terminate!(integrator) to halt the integration at a user-chosen stopping point.\nAnother common reason for this return code is due to implicit terminate! statements in some library callbacks. For example, SteadyStateCallback uses terminate! internally, so solutions which reach steady state will have a ReturnCode.Terminated state instead of a ReturnCode.Success state. Similarly, problems solved via SteadyStateDiffEq.jl will have this ReturnCode.Terminated state if a timestepping method is used to solve to steady state.\n\nProperties\n\nsuccessful_retcode = true\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.DtNaN","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.DtNaN","text":"ReturnCode.DtNaN\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because the dt of the integration was determined to be NaN and thus the solver could not continue.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because the automatic dt selection algorithm is used but the starting derivative has a NaN or Inf derivative term. Double check that the f(u0,p,t0) term is well-defined without NaN or Inf values.\nAnother common reason for this return code is because of a user set dt which is calculated to be a NaN. If solve(prob,alg,dt=x), double check that x is not NaN.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.MaxIters","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.MaxIters","text":"ReturnCode.MaxIters\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because the solver's iterations hit the maxiters either set by default or by the user in the solve/init command.\n\nNote about Nonlinear Optimization\n\nIn nonlinear optimization, many solvers (such as OptimizationOptimisers.Adam) do not have an exit criteria other than iters == maxiters. In this case, the solvers will iterate until maxiters and exit with a Success return code, as that is a successful run of the solver and not considered to be an error state. Solves with early termination criteria, such as Optim.BFGS exiting when the gradient is sufficiently close to zero, will give ReturnCode.MaxIters on exits which require the maximum iteration.\n\nCommon Reasons for Seeing this Return Code\n\nThis commonly occurs in ODE solving if a non-stiff method (e.g. Tsit5) is used in an algorithm choice for a stiff ODE. It is recommended that in such cases, one tries a stiff ODE solver.\nThis commonly occurs in optimization and nonlinear solvers if the tolerance on solve to too low and cannot be achieved due to floating point error or the condition number of the solver matrix. Double check that the chosen tolerance is numerically possible.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.MaxNumSub","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.MaxNumSub","text":"ReturnCode.MaxNumSub\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because during the solver's adaptivity, mesh length exceeded the max_num_subintervals either set by default or specified by users in the solver.\n\nCommon Reasons for Seeing this Return Code\n\nThis commonly occurs in BVP solving if the original mesh are too coarse or the tolerance are too stringent. It is recommended that in such cases, one tries to increase the default max_num_subintervals in solvers, or decrease the tolerance.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.MaxTime","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.MaxTime","text":"ReturnCode.MaxTime\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because the solver's timer hit maxtime either set by default or by the user in the solve/init command.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.DtLessThanMin","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.DtLessThanMin","text":"ReturnCode.DtLessThanMin\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because the dt of the integration was made to be less than dtmin, i.e. dt < dtmin.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because the integration is going unstable. As f(u,p,t) -> infinity, the time steps required by the solver to accurately handle the dynamics decreases. When it gets sufficiently small, dtmin, an exit is thrown as the solution is likely unstable. dtmin is also chosen to be around the value where floating point issues cause t + dt == t, and thus a dt of that size is impossible at floating point precision.\nAnother common reason for this return code is if domain constraints are set, such as by using isoutofdomain, but the domain constraint is incorrect. For example, if one is solving the ODE f(u,p,t) = -u - 1, one may think \"but I want a solution with u > 0 and thus I will set isoutofdomain(u,p,t) = u < 0. However, the true solution of this ODE is not positive, and thus what will occur is that the solver will try to decrease dt until it can give an accurate solution that is positive. As this is impossible, it will continue to shrink the dt until dt < dtmin and then exit with this return code.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Unstable","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Unstable","text":"ReturnCode.Unstable\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful and exited early because the unstable_check function, as given by the unstable_check common keyword argument (or its default), give a true at the current state.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because u contains a NaN or Inf value. The default unstable_check only checks for these values.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.InitialFailure","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.InitialFailure","text":"ReturnCode.InitialFailure\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful because the initialization process failed.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because the initialization process of a DAE solver failed to find consistent initial conditions, which can occur if the differentiation index of the DAE solver is too high. Most DAE solvers only allow for index-1 DAEs, and so an index-2 DAE will fail during this initialization. To solve this kind of problem, use ModelingToolkit.jl and its structural_simplify method to reduce the index of the DAE.\nAnother common reason for this return code is if the initial condition was not suitable for the numerical solve. For example, the initial point had a NaN or Inf. Or in optimization, this can occur if the initial point is outside of the bound constraints given by the user.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.ConvergenceFailure","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.ConvergenceFailure","text":"ReturnCode.ConvergenceFailure\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful because internal nonlinear solver iterations failed to converge.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because an inappropriate nonlinear solver was chosen. If fixed point iteration is used on a stiff problem, it will be faster by avoiding the Jacobian but it will make a stiff ODE solver not stable for stiff problems!\nFor nonlinear solvers, this can occur if certain threshold was exceeded. For example, in approximate jacobian solvers like Broyden, Klement, etc. if the number of jacobian resets exceeds the threshold, then this return code is given.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Failure","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Failure","text":"ReturnCode.Failure\n\nA failure exit state of the solver. If this return code is given, then the solving process was unsuccessful but no extra information is given.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for seeing this return code is because the solver is a wrapped solver (i.e. a Fortran code) which does not provide any extra information about its exit state. If this is from a Julia-based solver, please open an issue.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Infeasible","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Infeasible","text":"ReturnCode.Infeasible\n\nThe optimization problem was proven to be infeasible by the solver.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.ExactSolutionLeft","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.ExactSolutionLeft","text":"ReturnCode.ExactSolutionLeft\n\nThe success state of the solver. If this return code is given, then the solving process was successful, and the left solution was given.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for this return code is via a bracketing nonlinear solver, such as bisection, iterating to convergence is unable to give the exact f(x)=0 solution due to floating point precision issues, and thus it gives the first floating point value to the left for x.\n\nProperties\n\nsuccessful_retcode = true\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.ExactSolutionRight","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.ExactSolutionRight","text":"ReturnCode.ExactSolutionRight\n\nThe success state of the solver. If this return code is given, then the solving process was successful, and the right solution was given.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for this return code is via a bracketing nonlinear solver, such as bisection, iterating to convergence is unable to give the exact f(x)=0 solution due to floating point precision issues, and thus it gives the first floating point value to the right for x.\n\nProperties\n\nsuccessful_retcode = true\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.FloatingPointLimit","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.FloatingPointLimit","text":"ReturnCode.FloatingPointLimit\n\nThe success state of the solver. If this return code is given, then the solving process was successful, and the closest floating point value to the solution was given.\n\nCommon Reasons for Seeing this Return Code\n\nThe most common reason for this return code is via a nonlinear solver, such as Falsi, iterating to convergence is unable to give the exact f(x)=0 solution due to floating point precision issues, and thus it gives the closest floating point value to the true solution for x.\n\nProperties\n\nsuccessful_retcode = true\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.InternalLineSearchFailed","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.InternalLineSearchFailed","text":"ReturnCode.InternalLineSearchFailed\n\nInternal Line Search used by the algorithm has failed.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.InternalLinearSolveFailed","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.InternalLinearSolveFailed","text":"ReturnCode.InternalLinearSolveFailed\n\nThe linear problem inside another problem (for example inside a NonlinearProblem) could not be solved.\n\nCommon Reasons for Seeing this Return Code\n\nIf a rank-deficient matrix originated inside the nonlinear solve and the provided linear solver is incapable of handling those cases.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.ShrinkThresholdExceeded","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.ShrinkThresholdExceeded","text":"ReturnCode.ShrinkThresholdExceeded\n\nThe trust region radius was shrunk more times than the provided threshold.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.ReturnCode.Stalled","page":"SciMLSolutions","title":"SciMLBase.ReturnCode.Stalled","text":"ReturnCode.Stalled\n\nThe solution has stalled. This is only returned by algorithms for which stalling is a failure mode, such as on a NonlinearProblem where the found solution is larger than the accepted tolerance.\n\nProperties\n\nsuccessful_retcode = false\n\n\n\n\n\n","category":"constant"},{"location":"interfaces/Solutions/#SciMLBase.AbstractSciMLSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractSciMLSolution","text":"Union of all base solution types.\n\nUses a Union so that solution types can be <: AbstractArray\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractNoTimeSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNoTimeSolution","text":"abstract type AbstractNoTimeSolution{T, N} <: AbstractArray{T, N}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractTimeseriesSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractTimeseriesSolution","text":"abstract type AbstractTimeseriesSolution{T, N, A} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractNoiseProcess","page":"SciMLSolutions","title":"SciMLBase.AbstractNoiseProcess","text":"abstract type AbstractNoiseProcess{T, N, A, isinplace} <: RecursiveArrayTools.AbstractDiffEqArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractEnsembleSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractEnsembleSolution","text":"abstract type AbstractEnsembleSolution{T, N, A} <: RecursiveArrayTools.AbstractVectorOfArray{T, N, A}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractLinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractLinearSolution","text":"abstract type AbstractLinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractNonlinearSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractNonlinearSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractIntegralSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractIntegralSolution","text":"abstract type AbstractIntegralSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractSteadyStateSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractSteadyStateSolution","text":"abstract type AbstractNonlinearSolution{T, N} <: SciMLBase.AbstractNoTimeSolution{T, N}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractAnalyticalSolution","page":"SciMLSolutions","title":"SciMLBase.AbstractAnalyticalSolution","text":"abstract type AbstractAnalyticalSolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractODESolution","text":"abstract type AbstractODESolution{T, N, S} <: SciMLBase.AbstractTimeseriesSolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractDDESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDDESolution","text":"abstract type AbstractDDESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractRODESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractRODESolution","text":"abstract type AbstractRODESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Solutions/#SciMLBase.AbstractDAESolution","page":"SciMLSolutions","title":"SciMLBase.AbstractDAESolution","text":"abstract type AbstractDAESolution{T, N, S} <: SciMLBase.AbstractODESolution{T, N, S}\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Common_Keywords/#Common-Keyword-Arguments","page":"Common Keyword Arguments","title":"Common Keyword Arguments","text":"The following defines the keyword arguments which are meant to be preserved throughout all of the AbstractSciMLProblem cases (where applicable).","category":"section"},{"location":"interfaces/Common_Keywords/#Default-Algorithm-Hinting","page":"Common Keyword Arguments","title":"Default Algorithm Hinting","text":"To help choose the default algorithm, the keyword argument alg_hints is provided to solve. alg_hints is a Vector{Symbol} which describe the problem at a high level to the solver. The options are:\n\nThis functionality is derived via the benchmarks in SciMLBenchmarks.jl\n\nCurrently this is only implemented for the differential equation solvers.","category":"section"},{"location":"interfaces/Common_Keywords/#Output-Control","page":"Common Keyword Arguments","title":"Output Control","text":"These arguments control the output behavior of the solvers. It defaults to maximum output to give the best interactive user experience, but can be reduced all the way to only saving the solution at the final timepoint.\n\nThe following options are all related to output control. See the \"Examples\" section at the end of this page for some example usage.\n\ndense: Denotes whether to save the extra pieces required for dense (continuous) output. Default is save_everystep && !isempty(saveat) for algorithms which have the ability to produce dense output, i.e. by default it's true unless the user has turned off saving on steps or has chosen a saveat value. If dense=false, the solution still acts like a function, and sol(t) is a linear interpolation between the saved time points.\nsaveat: Denotes specific times to save the solution at, during the solving phase. The solver will save at each of the timepoints in this array in the most efficient manner available to the solver. If only saveat is given, then the arguments save_everystep and dense are false by default. If saveat is given a number, then it will automatically expand to tspan[1]:saveat:tspan[2]. For methods where interpolation is not possible, saveat may be equivalent to tstops. The default value is [].\nsave_idxs: Denotes the indices for the components of the equation to save. Defaults to saving all indices. For example, if you are solving a 3-dimensional ODE, and given save_idxs = [1, 3], only the first and third components of the solution will be outputted. Notice that of course in this case the outputted solution will be two-dimensional.\ntstops: Denotes extra times that the timestepping algorithm must step to. This should be used to help the solver deal with discontinuities and singularities, since stepping exactly at the time of the discontinuity will improve accuracy. If a method cannot change timesteps (fixed timestep multistep methods), then tstops will use an interpolation, matching the behavior of saveat. If a method cannot change timesteps and also cannot interpolate, then tstops must be a multiple of dt or else an error will be thrown. Default is [].\nd_discontinuities: Denotes locations of discontinuities in low order derivatives. This will force FSAL algorithms which assume derivative continuity to re-evaluate the derivatives at the point of discontinuity. The default is [].\nsave_everystep: Saves the result at every step. Default is true if isempty(saveat).\nsave_on: Denotes whether intermediate solutions are saved. This overrides the settings of dense, saveat and save_everystep and is used by some applications to manually turn off saving temporarily. Everyday use of the solvers should leave this unchanged. Defaults to true.\nsave_start: Denotes whether the initial condition should be included in the solution type as the first timepoint. Defaults to true.\nsave_end: Denotes whether the final timepoint is forced to be saved, regardless of the other saving settings. Defaults to true.\ninitialize_save: Denotes whether to save after the callback initialization phase (when u_modified=true). Defaults to true.\n\nNote that dense requires save_everystep=true and saveat=false.","category":"section"},{"location":"interfaces/Common_Keywords/#Stepsize-Control","page":"Common Keyword Arguments","title":"Stepsize Control","text":"These arguments control the timestepping routines.","category":"section"},{"location":"interfaces/Common_Keywords/#Basic-Stepsize-Control","page":"Common Keyword Arguments","title":"Basic Stepsize Control","text":"adaptive: Turns on adaptive timestepping for appropriate methods. Default is true.\nabstol: Absolute tolerance in adaptive timestepping. This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\nreltol: Relative tolerance in adaptive timestepping.  This is the tolerance on local error estimates, not necessarily the global error (though these quantities are related).\ndt: Sets the initial stepsize. This is also the stepsize for fixed timestep methods. Defaults to an automatic choice if the method is adaptive.\ndtmax: Maximum dt for adaptive timestepping. Defaults are package-dependent.\ndtmin: Minimum dt for adaptive timestepping. Defaults are package-dependent.","category":"section"},{"location":"interfaces/Common_Keywords/#Fixed-Stepsize-Usage","page":"Common Keyword Arguments","title":"Fixed Stepsize Usage","text":"Note that if a method does not have adaptivity, the following rules apply:\n\nIf dt is set, then the algorithm will step with size dt each iteration.\nIf tstops and dt are both set, then the algorithm will step with either a size dt, or use a smaller step to hit the tstops point.\nIf tstops is set without dt, then the algorithm will step directly to each value in tstops\nIf neither dt nor tstops are set, the solver will throw an error.","category":"section"},{"location":"interfaces/Common_Keywords/#Memory-Optimizations","page":"Common Keyword Arguments","title":"Memory Optimizations","text":"alias: an AbstractAliasSpecifier object that holds fields specifying which variables to alias when solving. For example, to tell an ODE solver to alias the u0 array, you can use an ODEAliases object, and the alias_u0 keyword argument, e.g. solve(prob,alias = ODEAliases(alias_u0 = true)). For more information on what can be aliased for each problem type, see the documentation for the AbstractAliasSpecifier associated with that problem type. Set to true to alias every variable possible, or to false to disable aliasing. Defaults to an AbstractAliasSpecifier instance with nothing for all fields, which tells the solver to use the default behavior.\ncache: pass a solver cache to decrease the construction time. This is not implemented for any of the problem interfaces at this moment.","category":"section"},{"location":"interfaces/Common_Keywords/#Miscellaneous","page":"Common Keyword Arguments","title":"Miscellaneous","text":"maxiters: Maximum number of iterations before stopping.\ncallback: Specifies a callback function that is called between iterations.\nverbose: Toggles whether warnings are thrown when the solver exits early. Defaults to true.","category":"section"},{"location":"interfaces/Common_Keywords/#Progress-Monitoring","page":"Common Keyword Arguments","title":"Progress Monitoring","text":"These arguments control the usage of the progressbar in the logger.\n\nprogress: Turns on/off the Juno progressbar. Default is false.\nprogress_steps: Numbers of steps between updates of the progress bar. Default is 1000.\nprogress_name: Controls the name of the progressbar. Default is the name of the problem type.\nprogress_message: Controls the message with the progressbar. Defaults to showing dt, t, the maximum of u.\n\nThe progress bars all use the Julia Logging interface in order to be generic to the IDE or programming tool that is used. For more information on how this is all put together, see this discussion.","category":"section"},{"location":"interfaces/Common_Keywords/#Error-Calculations","page":"Common Keyword Arguments","title":"Error Calculations","text":"If you are using the test problems (i.e. SciMLFunctions where f.analytic is defined), then options control the errors which are calculated. By default, any cheap error estimates are always calculated. Extra keyword arguments include:\n\ntimeseries_errors\ndense_errors\n\nfor specifying more expensive errors.","category":"section"},{"location":"interfaces/Common_Keywords/#Automatic-Differentiation-Control","page":"Common Keyword Arguments","title":"Automatic Differentiation Control","text":"See the Automatic Differentiation page for a full description of sensealg","category":"section"},{"location":"interfaces/Algorithms/#SciMLAlgorithms","page":"SciMLAlgorithms","title":"SciMLAlgorithms","text":"","category":"section"},{"location":"interfaces/Algorithms/#Definition-of-the-AbstractSciMLAlgorithm-Interface","page":"SciMLAlgorithms","title":"Definition of the AbstractSciMLAlgorithm Interface","text":"SciMLAlgorithms are defined as types which have dispatches to the function signature:\n\nCommonSolve.solve(prob::AbstractSciMLProblem, alg::AbstractSciMLAlgorithm; kwargs...)","category":"section"},{"location":"interfaces/Algorithms/#Algorithm-Specific-Arguments","page":"SciMLAlgorithms","title":"Algorithm-Specific Arguments","text":"Note that because the keyword arguments of solve are designed to be common across the whole problem type, algorithms should have the algorithm-specific keyword arguments defined as part of the algorithm constructor. For example, Rodas5 has a choice of autodiff::Bool which is not common across all ODE solvers, and thus autodiff is a algorithm-specific keyword argument handled via Rodas5(autodiff=true).","category":"section"},{"location":"interfaces/Algorithms/#Remake","page":"SciMLAlgorithms","title":"Remake","text":"Note that remake is applicable to AbstractSciMLAlgorithm types, but this is not used in the public API. It's used for solvers to swap out components like ForwardDiff chunk sizes.","category":"section"},{"location":"interfaces/Algorithms/#Common-Algorithm-Keyword-Arguments","page":"SciMLAlgorithms","title":"Common Algorithm Keyword Arguments","text":"Commonly used algorithm keyword arguments are:","category":"section"},{"location":"interfaces/Algorithms/#Traits","page":"SciMLAlgorithms","title":"Traits","text":"","category":"section"},{"location":"interfaces/Algorithms/#Abstract-SciML-Algorithms","page":"SciMLAlgorithms","title":"Abstract SciML Algorithms","text":"","category":"section"},{"location":"interfaces/Algorithms/#SciMLBase.isautodifferentiable","page":"SciMLAlgorithms","title":"SciMLBase.isautodifferentiable","text":"isautodifferentiable(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.allows_arbitrary_number_types","page":"SciMLAlgorithms","title":"SciMLBase.allows_arbitrary_number_types","text":"allows_arbitrary_number_types(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with direct automatic differentiation, i.e. can have algorithms like ForwardDiff or ReverseDiff attempt to differentiate directly through the solver.\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.allowscomplex","page":"SciMLAlgorithms","title":"SciMLBase.allowscomplex","text":"allowscomplex(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm is compatible with having complex numbers as the state variables.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.isadaptive","page":"SciMLAlgorithms","title":"SciMLBase.isadaptive","text":"isadaptive(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm uses adaptivity, i.e. has a non-quasi-static compute graph.\n\nDefaults to true.\n\n\n\n\n\nisadaptive(i::DEIntegrator)\n\nChecks if the integrator is adaptive\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.isdiscrete","page":"SciMLAlgorithms","title":"SciMLBase.isdiscrete","text":"isdiscrete(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm allows for discrete state values, such as integers.\n\nDefaults to false.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.forwarddiffs_model","page":"SciMLAlgorithms","title":"SciMLBase.forwarddiffs_model","text":"forwarddiffs_model(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm uses ForwardDiff.jl on the model function is called with ForwardDiff.jl\n\nDefaults to false as only pure-Julia algorithms can have this be true.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.forwarddiffs_model_time","page":"SciMLAlgorithms","title":"SciMLBase.forwarddiffs_model_time","text":"forwarddiffs_model_time(alg::AbstractDEAlgorithm)\n\nTrait declaration for whether an algorithm uses ForwardDiff.jl on the model f(u,p,t) function is called with ForwardDiff.jl on the t argument.\n\nDefaults to false as only a few pure-Julia algorithms (Rosenbrock methods) have this as true\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.has_init","page":"SciMLAlgorithms","title":"SciMLBase.has_init","text":"has_init(a) -> Bool\n\n\nTrait for specifying whether the passed algorithm supports init. Any inited object can solve!.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.has_step","page":"SciMLAlgorithms","title":"SciMLBase.has_step","text":"has_step(a) -> Bool\n\n\nTrait for specifying whether the passed algorithm supports step!, specifying a more direct control over the internal solver process. See https://docs.sciml.ai/SciMLBase/stable/interfaces/Init_Solve/#init-and-the-Iterator-Interface for more details.\n\n\n\n\n\n","category":"function"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractSciMLAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSciMLAlgorithm","text":"abstract type AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDEAlgorithm","text":"abstract type AbstractDEAlgorithm <: SciMLBase.AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractLinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractLinearAlgorithm","text":"abstract type AbstractLinearAlgorithm <: SciMLBase.AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractNonlinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractNonlinearAlgorithm","text":"abstract type AbstractNonlinearAlgorithm <: SciMLBase.AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractIntervalNonlinearAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractIntervalNonlinearAlgorithm","text":"abstract type AbstractIntervalNonlinearAlgorithm <: SciMLBase.AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractQuadratureAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractQuadratureAlgorithm","text":"abstract type AbstractIntegralAlgorithm <: SciMLBase.AbstractSciMLAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractOptimizationAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractOptimizationAlgorithm","text":"abstract type AbstractOptimizationAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractSteadyStateAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSteadyStateAlgorithm","text":"abstract type AbstractSteadyStateAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractODEAlgorithm","text":"abstract type AbstractODEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractSecondOrderODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSecondOrderODEAlgorithm","text":"abstract type AbstractSecondOrderODEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractRODEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractRODEAlgorithm","text":"abstract type AbstractRODEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractSDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDEAlgorithm","text":"abstract type AbstractSDEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractDAEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDAEAlgorithm","text":"abstract type AbstractDAEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractDDEAlgorithm","text":"abstract type AbstractDDEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Algorithms/#SciMLBase.AbstractSDDEAlgorithm","page":"SciMLAlgorithms","title":"SciMLBase.AbstractSDDEAlgorithm","text":"abstract type AbstractSDDEAlgorithm <: SciMLBase.AbstractDEAlgorithm\n\n\n\n\n\n","category":"type"},{"location":"interfaces/Init_Solve/#The-SciML-init-and-solve-Functions","page":"The SciML init and solve Functions","title":"The SciML init and solve Functions","text":"solve function has the default definition\n\nsolve(args...; kwargs...) = solve!(init(args...; kwargs...))\n\nThe interface for the three functions is as follows:\n\ninit(::ProblemType, args...; kwargs...)::IteratorType\nsolve!(::IteratorType)::SolutionType\n\nwhere ProblemType, IteratorType, and SolutionType are the types defined in your package.\n\nTo avoid method ambiguity, the first argument of solve, solve!, and init must be dispatched on the type defined in your package.  For example, do not define a method such as\n\ninit(::AbstractVector, ::AlgorithmType)","category":"section"},{"location":"interfaces/Init_Solve/#init-and-the-Iterator-Interface","page":"The SciML init and solve Functions","title":"init and the Iterator Interface","text":"init's return gives an IteratorType which is designed to allow the user to have more direct handling over the internal solving process. Because of this internal nature, the IteratorType has a less unified interface across problem types than other portions like ProblemType and SolutionType. For example, for differential equations this is the Integrator Interface designed for mutating solutions in a manner for callback implementation, which is distinctly different from the LinearSolve init interface which is designed for caching efficiency with reusing factorizations.","category":"section"},{"location":"interfaces/Init_Solve/#__solve-and-High-Level-Handling","page":"The SciML init and solve Functions","title":"__solve and High-Level Handling","text":"While init and solve are the common entry point for users, solver packages will mostly define dispatches on SciMLBase.__init and SciMLBase.__solve. The reason is because this allows for SciMLBase.init and SciMLBase.solve to have common implementations across all solvers for doing things such as checking for common errors and throwing high level messages. Solvers can opt-out of the high level error handling by directly defining SciMLBase.init and SciMLBase.solve instead, though this is not recommended in order to allow for uniformity of the error messages.","category":"section"},{"location":"interfaces/Differentiation/#sensealg","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","text":"Automatic differentiation control is done through the sensealg keyword argument. Hooks exist in the high level interfaces for solve which shuttle the definitions of automatic differentiation overloads to dispatches defined in DiffEqSensitivity.jl (should be renamed SciMLSensitivity.jl as it expands). This is done by first entering a top-level solve definition, for example:\n\nfunction solve(prob::AbstractDEProblem, args...; sensealg = nothing,\n        u0 = nothing, p = nothing, kwargs...)\n    u0 = u0 !== nothing ? u0 : prob.u0\n    p = p !== nothing ? p : prob.p\n    if sensealg === nothing && haskey(prob.kwargs, :sensealg)\n        sensealg = prob.kwargs[:sensealg]\n    end\n    solve_up(prob, sensealg, u0, p, args...; kwargs...)\nend\n\nsolve_up then drops down the differentiable arguments as positional arguments, which is required for the ChainRules.jl interface. Then the ChainRules overloads are written on the solve_up calls, like:\n\nfunction ChainRulesCore.frule(::typeof(solve_up), prob,\n        sensealg::Union{Nothing, AbstractSensitivityAlgorithm},\n        u0, p, args...;\n        kwargs...)\n    _solve_forward(prob, sensealg, u0, p, args...; kwargs...)\nend\n\nfunction ChainRulesCore.rrule(::typeof(solve_up), prob::SciMLBase.AbstractDEProblem,\n        sensealg::Union{Nothing, AbstractSensitivityAlgorithm},\n        u0, p, args...;\n        kwargs...)\n    _solve_adjoint(prob, sensealg, u0, p, args...; kwargs...)\nend\n\nDefault definitions then exist to throw an informative error if the sensitivity mechanism is not added:\n\nfunction _concrete_solve_adjoint(args...; kwargs...)\n    error(\"No adjoint rules exist. Check that you added `using DiffEqSensitivity`\")\nend\n\nfunction _concrete_solve_forward(args...; kwargs...)\n    error(\"No sensitivity rules exist. Check that you added `using DiffEqSensitivity`\")\nend\n\nThe sensitivity mechanism is kept in a separate package because of the high dependency and load time cost introduced by the automatic differentiation libraries. Different choices of automatic differentiation are then selected by the sensealg keyword argument in solve, which is made into a positional argument in the _solve_adjoint and other functions in order to allow dispatch.","category":"section"},{"location":"interfaces/Differentiation/#SensitivityADPassThrough","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"SensitivityADPassThrough","text":"The special sensitivity algorithm SensitivityADPassThrough is used to ignore the internal sensitivity dispatches and instead do automatic differentiation directly through the solver. Generally this sensealg is only used internally.","category":"section"},{"location":"interfaces/Differentiation/#Note-about-ForwardDiff","page":"Automatic Differentiation and Sensitivity Algorithms (Adjoints)","title":"Note about ForwardDiff","text":"ForwardDiff does not use ChainRules.jl and thus it completely ignores the special handling.","category":"section"},{"location":"#The-SciML-Common-Interface-for-Julia-Equation-Solvers","page":"Home","title":"The SciML Common Interface for Julia Equation Solvers","text":"The SciML common interface ties together the numerical solvers of the Julia package ecosystem into a single unified interface. It is designed for maximal efficiency and parallelism, while incorporating essential features for large-scale scientific machine learning such as differentiability, composability, and sparsity.\n\nThis documentation is made to pool together the docs of the various SciML libraries to paint the overarching picture, establish development norms, and document the shared/common functionality.","category":"section"},{"location":"#Domains-of-SciML","page":"Home","title":"Domains of SciML","text":"The SciML common interface covers the following domains:\n\nLinear systems (LinearProblem)\nDirect methods for dense and sparse\nIterative solvers with preconditioning\nNonlinear Systems (NonlinearProblem)\nRootfinding for systems of nonlinear equations\nInterval Nonlinear Systems\nBracketing rootfinders for nonlinear equations with interval bounds\nIntegrals (quadrature) (IntegralProblem)\nDifferential Equations\nDiscrete equations (function maps, discrete stochastic (Gillespie/Markov) simulations) (DiscreteProblem)\nOrdinary differential equations (ODEs) (ODEProblem)\nSplit and Partitioned ODEs (Symplectic integrators, IMEX Methods) (SplitODEProblem)\nStochastic ordinary differential equations (SODEs or SDEs) (SDEProblem)\nStochastic differential-algebraic equations (SDAEs) (SDEProblem with mass matrices)\nRandom differential equations (RODEs or RDEs) (RODEProblem)\nDifferential algebraic equations (DAEs) (DAEProblem and ODEProblem with mass matrices)\nDelay differential equations (DDEs) (DDEProblem)\nNeutral, retarded, and algebraic delay differential equations (NDDEs, RDDEs, and DDAEs)\nStochastic delay differential equations (SDDEs) (SDDEProblem)\nExperimental support for stochastic neutral, retarded, and algebraic delay differential equations (SNDDEs, SRDDEs, and SDDAEs)\nMixed discrete and continuous equations (Hybrid Equations, Jump Diffusions) (AbstractDEProblems with callbacks)\nOptimization (OptimizationProblem)\nNonlinear (constrained) optimization\n(Stochastic/Delay/Differential-Algebraic) Partial Differential Equations (PDESystem)\nFinite difference and finite volume methods\nInterfaces to finite element methods\nPhysics-Informed Neural Networks (PINNs)\nIntegro-Differential Equations\nFractional Differential Equations\n\nThe SciML common interface also includes ModelingToolkit.jl for defining such systems symbolically, allowing for optimizations like automated generation of parallel code, symbolic simplification, and generation of sparsity patterns.","category":"section"},{"location":"#Extended-SciML-Domain","page":"Home","title":"Extended SciML Domain","text":"In addition to the purely numerical representations of mathematical objects, there are also sets of problem types associated with common mathematical algorithms. These are:\n\nData-driven modeling\nDiscrete-time data-driven dynamical systems (DiscreteDataDrivenProblem)\nContinuous-time data-driven dynamical systems (ContinuousDataDrivenProblem)\nSymbolic regression (DirectDataDrivenProblem)\nUncertainty quantification and expected values (ExpectationProblem)","category":"section"},{"location":"#Inverse-Problems,-Parameter-Estimation,-and-Structural-Identification","page":"Home","title":"Inverse Problems, Parameter Estimation, and Structural Identification","text":"We note that parameter estimation and inverse problems are solved directly on their constituent problem types using tools like DiffEqFlux.jl. Thus for example, there is no ODEInverseProblem, and instead ODEProblem is used to find the parameters p that solve the inverse problem.","category":"section"},{"location":"#Common-Interface-High-Level","page":"Home","title":"Common Interface High Level","text":"The SciML interface is common as the usage of arguments is standardized across all of the problem domains. Underlying high level ideas include:\n\nAll domains use the same interface of defining a AbstractSciMLProblem which is then solved via solve(prob,alg;kwargs), where alg is a AbstractSciMLAlgorithm. The keyword argument namings are standardized across the organization.\nAbstractSciMLProblems are generally defined by a SciMLFunction which can define extra details about a model function, such as its analytical Jacobian, its sparsity patterns and so on.\nThere is an organization-wide method for defining linear and nonlinear solvers used within other solvers, giving maximum control of performance to the user.\nTypes used within the packages are defined by the input types. For example, packages attempt to internally use the type of the initial condition as the type for the state within differential equation solvers.\nsolve calls should be thread-safe and parallel-safe.\ninit(prob,alg;kwargs) returns an iterator which allows for directly iterating over the solution process\nHigh performance is key. Any performance that is not at the top level is considered a bug and should be reported as such.\nAll functions have an in-place and out-of-place form, where the in-place form is made to utilize mutation for high performance on large-scale problems and the out-of-place form is for compatibility with tooling like static arrays and some reverse-mode automatic differentiation systems.","category":"section"},{"location":"#User-Facing-Solver-Libraries","page":"Home","title":"User-Facing Solver Libraries","text":"DifferentialEquations.jl\nMulti-package interface of high performance numerical solvers of differential equations\nModelingToolkit.jl\nThe symbolic modeling package which implements the SciML symbolic common interface.\nLinearSolve.jl\nMulti-package interface for specifying linear solvers (direct, sparse, and iterative), along with tools for caching and preconditioners for use in large-scale modeling.\nNonlinearSolve.jl\nHigh performance numerical solving of nonlinear systems.\nIntegrals.jl\nMulti-package interface for high performance, batched, and parallelized numerical quadrature.\nOptimization.jl\nMulti-package interface for numerical solving of optimization problems.\nNeuralPDE.jl\nPhysics-Informed Neural Network (PINN) package for transforming partial differential equations into optimization problems.\nDiffEqOperators.jl\nAutomated finite difference method (FDM) package for transforming partial differential equations into nonlinear problems and ordinary differential equations.\nDiffEqFlux.jl\nHigh level package for scientific machine learning applications, such as neural and universal differential equations, solving of inverse problems, parameter estimation, nonlinear optimal control, and more.\nDataDrivenDiffEq.jl\nMulti-package interface for data-driven modeling, Koopman dynamic mode decomposition, symbolic regression/sparsification, and automated model discovery.\nSciMLExpectations.jl\nExtension to the dynamical modeling tools for calculating expectations.","category":"section"},{"location":"#Interface-Implementation-Libraries","page":"Home","title":"Interface Implementation Libraries","text":"SciMLBase.jl\nThe core package defining the interface which is consumed by the modeling and solver packages.\nDiffEqBase.jl\nThe core package defining the extended interface which is consumed by the differential equation solver packages.\nSciMLSensitivity.jl\nA package which pools together the definition of derivative overloads to define the common sensealg automatic differentiation interface.\nDiffEqNoiseProcess.jl\nA package which defines the stochastic AbstractNoiseProcess interface for the SciML ecosystem.\nRecursiveArrayTools.jl\nA package which defines the underlying AbstractVectorOfArray structure used as the output for all time series results.\nArrayInterface.jl\nThe package which defines the extended AbstractArray interface employed throughout the SciML ecosystem.","category":"section"},{"location":"#Using-Facing-Modeling-Libraries","page":"Home","title":"Using-Facing Modeling Libraries","text":"There are too many to name here and this will be populated when there is time!","category":"section"},{"location":"#Flowchart-Example-for-PDE-Constrained-Optimal-Control","page":"Home","title":"Flowchart Example for PDE-Constrained Optimal Control","text":"The following example showcases how the pieces of the common interface connect to solve a problem that mixes inference, symbolics, and numerics.\n\n(Image: )","category":"section"},{"location":"#External-Binding-Libraries","page":"Home","title":"External Binding Libraries","text":"diffeqr\nSolving differential equations in R using DifferentialEquations.jl with ModelingToolkit for JIT compilation and GPU-acceleration\ndiffeqpy\nSolving differential equations in Python using DifferentialEquations.jl","category":"section"},{"location":"#Solver-Libraries","page":"Home","title":"Solver Libraries","text":"There are too many to name here. Check out the SciML Organization Github Page for details.","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"section"},{"location":"#Reproducibility","page":"Home","title":"Reproducibility","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>\n\nusing Pkg # hide\nPkg.status() # hide\n\n</details>\n\n<details><summary>and using this machine and Julia version.</summary>\n\nusing InteractiveUtils # hide\nversioninfo() # hide\n\n</details>\n\n<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>\n\nusing Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide\n\n</details>\n\nusing TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"section"},{"location":"interfaces/Array_and_Number/#arrayandnumber","page":"SciML Container (Array) and Number Interfaces","title":"SciML Container (Array) and Number Interfaces","text":"We live in a society, and therefore there are rules. In this tutorial we outline the rules which are required on container and number types which are allowable in SciML tools.\n\nwarn: Warn\nIn general as of 2023, strict adherence to this interface is an early work-in-progress. If anything does not conform to the documented interface, please open an issue.\n\nnote: Note\nThere are many types which can work with a specific solver that do satisfy this interface. Many times as part of prototyping you may want to side-step the high level interface checks in order to simply test whether a new type is working. To do this, set interface_checks = false as a keyword argument to init/solve to bypass any of the internal interface checks. This means you will no longer get a nice high-level error message and instead it will attempt to use the type without restrictions. Note that not every problem/solver has implemented this new keyword argument as of 2023.","category":"section"},{"location":"interfaces/Array_and_Number/#Note-About-Wrapped-Solvers","page":"SciML Container (Array) and Number Interfaces","title":"Note About Wrapped Solvers","text":"Due to limitations of wrapped solvers, any solver that is a wrapped solver from an existing C/Fortran code is inherently limited to Float64 and Vector{Float64} for its operations. This includes packages like Sundials.jl, LSODA.jl, DASKR.jl, MINPACK.jl, and many more. This is fundamental to these solvers and it is not expected that they will allow the full set of SciML types in the future. If more abstract number/container definitions are required, then these are not the appropriate solvers to use.","category":"section"},{"location":"interfaces/Array_and_Number/#SciML-Number-Types","page":"SciML Container (Array) and Number Interfaces","title":"SciML Number Types","text":"The number types are the types used to define the dependent variables (i.e. u0) and the independent variables (t or tspan). These two types can be different, and can have different restrictions depending on the type of solver which is employed. The following rules for a Number type are held in general:\n\nNumber types can be used in SciML directly or in containers. If a problem defines a value like u0 using a Number type, the out-of-place form must be used for the problem definition.\nx::T + y::T = z::T\nx::T * y::T = z::T\noneunit(x::T)::T\none(x::T) * oneunit(x::T) = z::T\nt::T2 * x::T + y::T = z::T for T2 a time type and T the dependent variable type (this includes the muladd equivalent form).\n\nAdditionally, the following rules apply to subsets of uses:","category":"section"},{"location":"interfaces/Array_and_Number/#Adaptive-Number-Types","page":"SciML Container (Array) and Number Interfaces","title":"Adaptive Number Types","text":"x::T / y::T = z::T\nDefault choices of norms can assume sqrt(x::T)::T exists. If internalnorm is overridden then this may not be required (for example, changing the norm to inf-norm).\nx::T ^ y::T = z::T","category":"section"},{"location":"interfaces/Array_and_Number/#Time-Types-(Independent-Variables)","page":"SciML Container (Array) and Number Interfaces","title":"Time Types (Independent Variables)","text":"If a solver is time adaptive, the time type must be a floating point number. Rational is only allowed for non-adaptive solves.","category":"section"},{"location":"interfaces/Array_and_Number/#SciML-Container-(Array)-Types","page":"SciML Container (Array) and Number Interfaces","title":"SciML Container (Array) Types","text":"Container types are types which hold number types. They can be used to define objects like the state vector (u0) of a problem. The following operations are required in a container type to be used with SciML solvers:\n\nBroadcast is defined according to the Julia broadcast interface.\nThe container type correctly defines interface overloads to satisfy the ArrayInterface.jl specification.\nArrayInterface.zeromatrix(x::T)::T2 defines a compatible matrix type (see below)\neltype(x::T)::T2 is a compatible Number type.\nx::T .+ y::T = z::T (i.e. broadcast similar is defined to be type-presurving)\nIndexing is only required if ArrayInterface.fast_scalar_indexing(x::T)==true. If true, scalar indexing x[i] is assumed to be defined and run through all variables.\n\nnote: Note\n\"eltype(x::T)::T2 is a compatible Number type\" excludes Array{Array{T}} types of types. However, recursive vectors can conformed to the interface with zero overhead using tools from RecursiveArrayTools.jl such as VectorOfArray(x). Since this greatly simplifies the interfaces and the ability to check for correctness, doing this wrapping is highly recommended and there are no plans to relax this requirement.\n\nAdditionally, the following rules apply to subsets of uses:","category":"section"},{"location":"interfaces/Array_and_Number/#SciML-Mutable-Array-Types","page":"SciML Container (Array) and Number Interfaces","title":"SciML Mutable Array Types","text":"similar(x::T)::T\nzero(x::T)::T\nz::T .= x::T .+ y::T is defined\nz::T .= x::T .* y::T is defined\nz::T .= t::T2 .* x::T where T2 is the time type (a Number) and T is the container type.\n(Optional) Base.resize!(x,i) is required for resize!(integrator,i) to be supported.","category":"section"},{"location":"interfaces/Array_and_Number/#SciML-Matrix-(Operator)-Type","page":"SciML Container (Array) and Number Interfaces","title":"SciML Matrix (Operator) Type","text":"Note that the matrix type may not match the type of the initial container u0. An example is ComponentMatrix as the matrix structure corresponding to a ComponentArray. However, the following actions are assumed to hold on the resulting matrix type:\n\nsolve(LinearProblem(A::T,b::T2),linsolve) must be defined for a solver to work on a given SciML matrix type T2.\nIf the matrix is an operator, i.e. a lazy construct, it should conform to the SciMLOperators interface.\nIf not a SciMLOperator, diagind(W::T) should be defined and @view(A[idxs])=@view(A[idxs]) + λ::T","category":"section"},{"location":"interfaces/PDE/#The-PDE-Definition-Interface","page":"The PDE Definition Interface","title":"The PDE Definition Interface","text":"While ODEs u = f(upt) can be defined by a user-function f, for PDEs the function form can be different for every PDE. How many functions, and how many inputs? This can always change. The SciML ecosystem solves this problem by using ModelingToolkit.jl to define PDESystem, a high-level symbolic description of the PDE to be consumed by other packages.\n\nThe vision for the common PDE interface is that a user should only have to specify their PDE once, mathematically, and have instant access to everything as simple as a finite difference method with constant grid spacing, to something as complex as a distributed multi-GPU discontinuous Galerkin method.\n\nThe key to the common PDE interface is a separation of the symbolic handling from the numerical world. All of the discretizers should not \"solve\" the PDE, but instead be a conversion of the mathematical specification to a numerical problem. Preferably, the transformation should be to another ModelingToolkit.jl AbstractSystem via a symbolic_discretize dispatch, but in some cases this cannot be done or will not be performant. Thus in some cases, only a discretize definition is given to a AbstractSciMLProblem, with symbolic_discretize simply providing diagnostic or lower level information about the construction process.\n\nThese elementary problems, such as solving linear systems Ax=b, solving nonlinear systems f(x)=0, ODEs, etc. are all defined by SciMLBase.jl, which then numerical solvers can all target these common forms. Thus someone who works on linear solvers doesn't necessarily need to be working on a Discontinuous Galerkin or finite element library, but instead \"linear solvers that are good for matrices A with properties ...\" which are then accessible by every other discretization method in the common PDE interface.\n\nSimilar to the rest of the AbstractSystem types, transformation and analyses functions will allow for simplifying the PDE before solving it, and constructing block symbolic functions like Jacobians.","category":"section"},{"location":"interfaces/PDE/#Constructors","page":"The PDE Definition Interface","title":"Constructors","text":"","category":"section"},{"location":"interfaces/PDE/#Domains-(WIP)","page":"The PDE Definition Interface","title":"Domains (WIP)","text":"Domains are specifying by saying indepvar in domain, where indepvar is a single or a collection of independent variables, and domain is the chosen domain type. A 2-tuple can be used to indicate an Interval. Thus forms for the indepvar can be like:\n\nt ∈ (0.0, 1.0)\n(t, x) ∈ UnitDisk()\n[v, w, x, y, z] ∈ VectorUnitBall(5)","category":"section"},{"location":"interfaces/PDE/#Domain-Types-(WIP)","page":"The PDE Definition Interface","title":"Domain Types (WIP)","text":"Interval(a,b): Defines the domain of an interval from a to b (requires explicit import from DomainSets.jl, but a 2-tuple can be used instead)","category":"section"},{"location":"interfaces/PDE/#discretize-and-symbolic_discretize","page":"The PDE Definition Interface","title":"discretize and symbolic_discretize","text":"The only functions which act on a PDESystem are the following:\n\ndiscretize(sys,discretizer): produces the outputted AbstractSystem or AbstractSciMLProblem.\nsymbolic_discretize(sys,discretizer): produces a debugging symbolic description of the discretized problem.","category":"section"},{"location":"interfaces/PDE/#Boundary-Conditions-(WIP)","page":"The PDE Definition Interface","title":"Boundary Conditions (WIP)","text":"","category":"section"},{"location":"interfaces/PDE/#Transformations","page":"The PDE Definition Interface","title":"Transformations","text":"","category":"section"},{"location":"interfaces/PDE/#Analyses","page":"The PDE Definition Interface","title":"Analyses","text":"","category":"section"},{"location":"interfaces/PDE/#Discretizer-Ecosystem","page":"The PDE Definition Interface","title":"Discretizer Ecosystem","text":"","category":"section"},{"location":"interfaces/PDE/#NeuralPDE.jl:-PhysicsInformedNN","page":"The PDE Definition Interface","title":"NeuralPDE.jl: PhysicsInformedNN","text":"NeuralPDE.jl defines the PhysicsInformedNN discretizer which uses a DiffEqFlux.jl neural network to solve the differential equation.","category":"section"},{"location":"interfaces/PDE/#MethodOfLines.jl:-MOLFiniteDifference-(WIP)","page":"The PDE Definition Interface","title":"MethodOfLines.jl: MOLFiniteDifference (WIP)","text":"MethodOfLines.jl defines the MOLFiniteDifference discretizer which performs a finite difference discretization using the DiffEqOperators.jl stencils. These stencils make use of NNLib.jl for fast operations on semi-linear domains.","category":"section"}]
}
